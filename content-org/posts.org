#+TITLE: Samarth's Blog
#+HUGO_BASE_DIR: ../
#+OPTIONS:  ^:nil
#+HUGO_SECTION: posts/
#+HUGO_AUTO_SET_LASTMOD: t
#+DATE: 2020-06-29
#+STARTUP: logdone

* TODO Teaching University CS from First Principles                      :PL:
:PROPERTIES:
:EXPORT_FILE_NAME: university_cs_from_first_principles
:END:

I'm a fourth-year undergrad CS student at the University of Virginia. UVA has a decently-rated CS curriculum geared towards producing capable software engineers. Based on my experience, the CS department tends to focus on more "practical" software engineering and less on theoretical computer science.

This is a really long post so here's the TLDR:
  - I think that CS curriculums should be structured around [[https://www.wikipedia.com/wiki/First_principle][First Principles]] to ensure that most students who graduate have a rock-solid base of knowledge without any major gaps. There are only two ways to achieve this:
    - Lambda Calculus: Start from logic and math, and use a language based on the Lambda Calculus to work your way up the stack (this is better in my opinion). Then switch to using C-like languages based on the Turing Machine in later courses. This does not mean that an intro course should even mention Lambda Calculus! It's just a useful frame of reference.
    - Turing Machine: Start from von Neumann architecture and machine code and work your way up the stack using a language based on the Turing Machine. Then switch to the Lambda Calculus approach in later courses.
  - CS curriculums should offer two introductory courses: one for potential majors and another for students who want to learn some basic programming.
    - The programming course for non-majors should be taught in Python and is basically what most intro CS courses are like today.
    - The course for majors should be taught in a way that completely evens the playing field for those who have some previous programming experience and those who have none. It should also encourage students to program using concepts they have learned from math and logic (First Principles) instead of teaching students how to think like a machine. I argue that Racket is a good language for teaching such a course.
  - Universities want to produce graduates who can get good-paying jobs or go to graduate school.
    - CS graduates who have extremely stong fundamentals are more valuable for the workplace and will find it easier to improve and/or maintain codebases. They will also have an easier time learning new languages and technologies.
    - Graduate schools want students with strong fundamentals in theoretical computer science who know how to apply theory to solve interesting problems and write papers that will get published.

For reference, UVA has two different CS degrees---BA and BS. I'm a BA which means I don't have to take some courses like OS and Theory of Computation but instead am required to take some interdisciplinary courses in the College of Arts and Sciences that somewhat relate to computing. I will not be focusing on those interdisciplinary courses in this post. The only required BS course that I did not end up taking is Advanced Software Development (it focused on web development in Django, and I already had some experience with that in an internship). BA students cannot take Digital Logic Design so that one doesn't count.

Here are the courses I have taken so far:

| Semester | Course Name                   | Course Number |
|----------+-------------------------------+---------------|
|        1 | *Introduction to Programming*   | CS 1111       |
|        2 | *Discrete Mathematics*          | CS 2102       |
|        2 | *Software Development Methods*  | CS 2110       |
|        3 | *Program & Data Representation* | CS 2150       |
|        4 | *Theory of Computation*         | CS 3102       |
|        4 | *Algorithms*                    | CS 4102       |
|        5 | *Computer Architecture*         | CS 3330       |
|        5 | Programming Languages         | CS 4610       |
|        6 | *Operating Systems*             | CS 4414       |
|        7 | Compilers                     | CS 4620       |
|        7 | Artificial Intelligence       | CS 4710       |
|        8 | Software Logic                | CS 4501       |
|        8 | Compilers                     | CS 6620       |

The required courses (for a BS) that I have taken are in bold.

With the exception of my 8th (current) semester, this is pretty representative of the types of courses that a typical CS student at UVA will take. Most people end up taking Advanced Software Development and Databases at some point but tend to avoid theory-heavy courses like Programming Languages and Compilers. UVA's CS curriculum has changed in the past couple years but the core content is mostly the same.

** My Problem with Intro CS Courses and a Possible Solution

Before I say anything else, I want to make it clear that I am in no way criticizing individual CS professors. They have all been incredibly helpful and really want students to succeed. I just disagree with some of the topics that the curriculum emphasizes and the way that the curriculum is fundamentally structured (the new CS course structure at UVA does not solve these problems but is a step in the right direction).

I believe that to truly understand something, you need to learn it from [[https://www.wikiwand.com/en/First_principle][First Principles]]. No math class would ever consider teaching multiplication before addition. Likewise, there are really only two ways to teach an introductory CS course from First Principles
    - Lambda Calculus (thinking like a mathematician): Start from logic and math, and use a language based on the Lambda Calculus to work your way up the stack. Then switch to using C-like languages based on the Turing Machine in later courses and work your way up the stack from Machine Code.
    - Turing Machine (thinking like a computer): Start from von Neumann architecture and machine code and work your way up the stack using a language based on the Turing Machine. Then switch to using Lisp- or ML-like languages based on the Lambda Calculus in later courses.

Note that I don't recommend actually introducing Lambda Calculus or Turing Machines this early. They are just useful ways to categorize programming languages and ways of thinking.

[[https://jamesclear.com/first-principles][First Principles]] is an important framework for thinking. SpaceX would never have made a relatively cheap rocket that not only is capable of sending astronauts to the International Space Station, but can autonomously land in order to be reused for future flights. The same thing applies to Computer Science---we will be doomed to never make progress unless we have a strong understanding of the fundamentals of computing.

The first CS class that students take is "Introduction to Programming" which is taught in Python. Python is a fine language, but I don't think that it's a good choice for an introductory CS course for prospective CS majors.

*** The Problem with Imperative Languages

Let's look at how Python handles variables. To someone who has never seen a computer program before, what do you think they would say this program does?

#+begin_src python
x = 2
x = x + 1
#+end_src

I'd be willing to bet that most students would say that =x = x + 1= is impossible. How can =x= be equal to itself plus one? That doesn't make any sense! In math, a variable is something that is bound to a value---you can't change it later on. In CS jargon, this is called immutability.

Brown University uses the Racket programming language for its intro course. Racket makes setting variables explicit so it's an improvement over Python, although its syntax is unusual:

#+begin_src scheme
(let [[x 2]]
  (set! x (+ x 1)))
#+end_src

Prolog, a logic programming language, is one of the few languages that actually follows the math.

#+begin_src prolog
?- X = 2, X = X + 1.
false.
#+end_src

=== is /equality/ in Prolog, not assignment. The Prolog program is trying to answer the question "is it true that when =X= is equal to 2, =X= is equal to =X= plus 1?" Naturally, the answer is =false=---such a question doesn't even make sense in a language like Prolog.

Learning any kind of imperative language like Python, Java, C, etc. as a beginner will not be intuitive. For someone to fully understand what Python is doing when it executes =x = x + 1=, they will need to understand references, de-referencing variables, l-values, r-values, expressions, and statements. The =x= on the left-hand-side of the equals sign is the l-value which means that it's referring to the variable. The =x= on the right-hand-side of the equals sign is an r-value inside of an expression which means that it's the value in memory that the variable =x= points to (the number 2). Those two Python =x= variables are not the same, even though they look the same. On the other hand, the Prolog program is pretty much executable math and logic---=X= is =X=.

OCaml, a functional language in the ML family, makes all of the steps in the Python program more explicit:

#+begin_src ocaml
let x = ref 1 in
x := !x + 1
#+end_src

Here we bind =x= to a reference containing the value 1. Incrementing =x= involves de-referencing the reference to =x= via the =!= operator to get its value and assigning =x= to its old value plus one. Binding values uses === and assignment uses =:==. In my opinion, this is much more clear (even though de-referencing with =!= still looks a little weird to me since I'm so used to C-like languages). Furthermore, you don't even have to know what a statement is---everything in OCaml is an expression that returns something.

However, even introducing the concept of references this early doesn't make much sense to me. To actually understand what a reference is, you need to understand how computers use memory---a topic that UVA's CS curriculum does not cover until CS 2150 (or the equivalent low-level programming course taught in C or C++).

Let's go back to the topic of teaching from First Principles. I said there are only two ways to structure an intro CS course this way: bottom-up or top-down. Either way works, but I think it's far easier to justify the top-down approach. Students would probably get bored if all they can do for the first few classes is flip bits and write Assembly. With a top-down approach, they can write high-level code that does interesting things within a few short days.

Python is supposed to be a high-level language though! That's why so many CS departments start with Python instead of C, right? The problem is not that Python is "high-level", but that it forces the programmer to think like a machine.

Let's go back to the earlier example:

#+begin_src python
x = 1
x = x + 1
#+end_src

To understand what this does, you have to think about it in the following steps:
 - Declare the variable =x= and set it to 1
 - Add 1 to the value of =x=
 - Set the new value of =x= to be the incremented value

This feels pretty low-level to me. You have to go line-by-line and execute the insructions in your head statement-by-statement. There's relatively little mathematical or logical thinking involved.

Python, Java, and other such languages have rules whether a type is implicitly a value or a reference. This makes them harder for beginners to learn because it's another case to memorize.

This prints 1 because =x= is an integer, a value type:

#+begin_src python :results output
def increment(x):
    x = x + 1

n = 1
increment(n)
print(n)
#+end_src

#+RESULTS:
: 1

However, this example prints 2 because =x= is an object, a reference type:

#+begin_src python :results output
class Num:
    def __init__(self):
        self.val = 1


def increment(x):
    x.val = x.val + 1


n = Num()
increment(n)
print(n.val)
#+end_src

#+RESULTS:
: 2

In C, you have to be explicit whether a type is a value or a reference:

#+begin_src C :includes <stdio.h>
  void increment(int x) {
      x = x + 1;
  }

  int main() {
      int n = 1;
      increment(n);
      printf("%d\n", n);
  }
#+end_src

#+RESULTS:
: 1

C prints 1 because functions have value semantics unless they explicitly use pointers. This is the C version of the Python code using objects:

#+begin_src C :includes <stdio.h>
  void increment(int *x) {
      *x = *x + 1;
  }

  int main() {
      int n = 1;
      increment(&n);
      printf("%d\n", n);
  }
#+end_src

#+RESULTS:
: 2

Here it prints 2 because =x= is explicitly passed by-reference to the =increment= function. Languages like Python and Java have reference semantics where all non-"primitive" types are implicitly references, just like C pointers.

Learning about this made sense at a surface level during my intro CS course, but it never really clicked until 2 semesters later when I finally learned about pointers in C++. We never learned about pass-by-reference from First Principles.

I think that using languages with implicit reference semantics to teach an introductory CS class is a bad idea if you're trying to adhere to the First Principles approach, but unfortunately, this rules out pretty much every popular programming language except C and C++. However, even C and C++ are not ideal because they force you to think like the machine, and we're trying to stick to high-level math and logic. This means that the only available languages to teach intro CS are functional or logic languages.

**** The Case for Using an Obscure Functional/Logic Language for Intro CS

Let's address some rebuttals:
 - Students want to learn skills that they can actually use. Python is a useful language and no one cares about obscure languages like Lisp, ML, or Prolog.
   - This is an intro CS course for potential CS majors. No one knows what is or isn't "useful" yet. There's still plenty of time later on to learn Python and Java, but a language with intuitive syntax and semantics (for beginners with no prior exposure to imperative languages) is a great fit for an intro course.
 - Students with previous experience in languages like Python and JavaScript will be at a disadvantage.
   - Yes, this is potentially a good thing because an unfamiliar language will even the playing field and ensure that everyone learns the same material. At the end of the day, this course is about teaching CS fundamentals, not teaching general-purpose programming, and a language like Racket or Prolog excels at this.
 - Students will be turned off by the unfamiliar syntax (especially for Lisps like Racket).
   - Unfamiliar syntax can be a good thing. If taught well, Lisp syntax is extremely simple and can be learned in far less time than supposedly simple languages like Python. It also introduces the concept of data structures early on---your program is itself a list. This will also expose students to a way of thinking about syntax which will help in later courses when they learn languages like C and Python---syntax isn't that important and its main use is to enable different semantics. There are zero corner-cases in Lisp syntax and only a few in Prolog or ML (the programming language family, not Machine Learning), where in Python, you have to memorize dozens of corner-cases.

Here's an example of a corner-case in Python's syntax that doesn't make sense until you understand the difference between expressions and statements. This difference doesn't exist in a Lisp or ML dialect because everything is an expression.

This doesn't work because =if= is a statement:

#+begin_src python
x = if True:
      1
    else:
      2
#+end_src

#+RESULTS:

An =if= expression looks completely different:

#+begin_src python
x = 1 if True else 2
#+end_src

In Racket, it looks like this---everything in the language is an expression wrapped in either square brackets or parentheses:

#+begin_src scheme
(let [[x (if true 1 2)]]
   ;; use x...
)
#+end_src

Here's another case for teaching a functional language early on: historically imperative languages are slowly getting features that have been in functional languages for decades. This is similar to the time when procedural languages like PHP and Perl got OO features 15-25 years ago after the rise of Java.
  - C++: Lambdas, optional types, concepts (similar to Haskell type classes)
  - Java: Lambdas, streams, optional types (like Haskell's =Maybe= or OCaml's =Option.t=), data records
  - PHP: closures ([[https://nullprogram.com/blog/2019/09/25/][sort of...]])
  - Python: Pattern matching, data classes, optional types

Rust, one of the most popular new imperative languages, has immutable variables by default, [[https://en.wikipedia.org/wiki/Value_semantics][value semantics]], higher-order functions, and proper lexical closures. Go and Swift come close but choose to make immutability opt-in and don't have consistent value semantics.

Closures and higher-order functions are everywhere in JavaScript code, and JS is consistently the most or second-most popular programming language in the world.

Universities should teach new ideas, not stick to decades-old "best practices". To get with the times, CS curriculums need to place a greater emphasis on functional and logic programming. If nothing else, students should at least learn about immutability and higher-order functions.

**** A Proposed Syllabus for CS 101

I'll admit that I have zero experience designing syllabi but I'll give this my best shot. Note that this is not language-specific and the topics (in order) will mostly look like this:

- Early CS History: Ada, Turing, Church, etc. This is optional but might help put things into perspective
- Strings, and numbers (all immutable, Unicode should be introduced early)
- Expressions
- Variables (immutable)
- The concept of abstraction (this is crucial to understand because all of CS is just layers of abstraction)
- Abstracting expressions with functions
- Conditional expressions and booleans
- Recursion
- Debugging techniques such as tracing function execution, printing expressions, and stepping through code
- Abstracting functions with higher-order functions
- Lists
- Syntax sugar
- Hashmaps and trees (use lists to build these)
- Basic algorithms like searching and sorting
- Applying these techniques to make a game or some other type of interactive GUI

This follows First Principles because students already have an intuitive sense for numbers, expressions, variables, and functions from math. A string is just text. Conditional expressions and booleans are also rooted in math and fundamental logic. I chose to introduce lists after higher-order functions because lists can be implemented in terms of functions---this goes back to Lambda Calculus. Syntax sugar is a fancy way of explaining substitution---lists represented as nested functions can be "de-sugared" into regular lists like =[1, 2, 3]=.

Teaching recursion early will give students a massive advantage when they start learning about more complex algorithms like BFS and DFS later on. Once recursion is intuitive, control structures like for- and while-loops will be trivial to understand, and can be implemented using recursion.

I also think that CS courses should place a much greater emphasis on debugging since it's an extremely useful skill to quickly find bugs. Professional programmers spend a lot of time debugging and some coding interviews even have a dedicated debugging section. Profiling is another crucial skill that probably doesn't fit in an intro course, but should be a major component of any lecture involving optimization. Profilers are valuable tools, yet I was never taught how to use one in school.

**** The Case for Racket (a Lisp dialect)

Quick disclaimer: I've never really used Racket myself but have read some second-hand accounts of it and some of the documentation. I do have experience with Lisp (Clojure, Emacs Lisp, and a bit of Common Lisp), Prolog, and ML (Standard ML and OCaml).

Racket is fork of Scheme which is a dialect of Lisp. In my opinion, Scheme is the second simplest programming language (the simplest is Forth, but the two are pretty close). Simple languages are ideal for teaching and avoid a lot of confusion down the line when covering more advanced topics.

One of the major criticisms against teaching Lisp is its weird syntax. I'll admit that Lisp syntax is not ideal for real-world programming for a number of reasons that I won't get into in this post. However, it's great for beginners. Once you get used to the syntax (which only takes around 30 minutes), Lisp allows you to focus on your actual program instead of worrying about trivial things like where to place a comma or semicolon. It also gives you an intuitive sense for lists and trees, since a Lisp program is basically just the program's Abstract Syntax Tree.

MIT used to teach its introductory CS class in Scheme but [[https://www.wisdomandwonder.com/link/2110/why-mit-switched-from-scheme-to-python][switched to Python]] over 10 years ago. Their reasoning is perfectly valid, but a modern Scheme descendant like Racket has plenty of libraries for [[https://docs.racket-lang.org/framework/index.html][GUI]] and [[https://docs.racket-lang.org/quick/][interactive programming]] that will engage students. I also argued above that Python is a poor choice for the intro course of a CS curriculum based on First Principles, even though it has a fantastic library ecosystem. Yes, programming today is mostly gluing existing pieces of software together and keeping legacy code from falling apart, but that's no excuse for not teaching students how all software fundamentally works.

Racket has a great IDE called DrRacket with support for interactive programming. Having a REPL, a shell that allows you to interactively execute small snippets of code without having to recompile your whole program, is a crucial feature for any begginer-friendly programming language. DrRacket is easy to install on all platforms and is easy to use.

As opposed to many other obscure programming languages, Racket has excellent documentation that is geared towards beginners. The error messages are also pretty good. Python has one of the better official documentation stories from what I've seeen, but Racket's official docs are top of the line. Typed Racket (a static typing system for Racket implemented in the language itself) might be more useful than the core dynamic Racket because it will force students to think about types early (which they have to do in dynamically-typed languages anyways).

No one really uses Racket in industry and that's perfectly okay. I don't think that any course after CS 101 should use Racket, but it's great for teaching the fundamentals. [[https://github.com/racket/racket/wiki/Courses-using-Racket][Multiple universities]] use the language so there is plenty of teaching material.

Here are some other potential languages and reasons why they're not as good of a fit:
- Prolog (unpopular option for intro CS but should definitely be taught in a later course, logic programming is too far-removed from imperative... it's easier to switch between functional and imperative languages, not a lot of good documentation)
- OCaml (currying by default is confusing and makes it harder to teach, GUI ecosystem is lacking, documentation isn't very good but is improving)
- Clojure (the language is fantastic since everything is immutable but you need to know Java in order to read the error messages... this might be improved in the future)
- Haskell (lazy evaluation is nice coming from math but it's too far-removed from eagerly-evaluated imperative languages, error messages can be difficult to understand)
- Standard ML, Scheme (not a lot of documentation or libraries)
* DONE Typed APIs in Python with dataclasses and NamedTuples :programming:python:
CLOSED: [2020-08-13 Thu 13:35]
:PROPERTIES:
:EXPORT_FILE_NAME: typed_apis_in_python
:END:

Why would Python programmers ever care about types? While Python doesn't check any types statically (before running the program), it does perform extensive run-time type checking. Checking types at run-time without any implicit casts makes the language strongly-typed and dynamically-typed, as opposed to a language like C which is weakly-typed and statically-typed. This is an important distinction, but I won't go over the differences between strong and weak typing in this post.

Newer versions of Python 3 have support for type annotations which gives the programmer some more information about types. Tools like =mypy= perform some basic static type checking. However, these static type-checkers are not all-powerful and sometimes it's useful to provide some extra type-safety dynamically at run-time.

** The API

Imagine you're writing a Python script that uses a stock market API. The API provides a GET method called =get_stocks= which returns some JSON data containing information about three very specific stocks you're interested in (this is important because we know exactly what data the API method will return and therefore can model it). This is a bit hand-wavy, but the actual API call doesn't matter---we only care about the JSON return value.

#+begin_src python :session stock-session :results output :exports both
import json
from pprint import pprint

def get_stocks() -> str:
    """
    API method returning some JSON data
    """

    return json.dumps(
        {
            "TSLA": {"price": "1000.00"},
            "AMZN": {"price": "3000.00"},
            "AAPL": {"price": "400.00"}
        }
    )


stock_data = get_stocks()
pprint(stock_data)
#+end_src

#+results:
: ('{"TSLA": {"price": "1000.00"}, "AMZN": {"price": "3000.00"}, "AAPL": '
:  '{"price": "400.00"}}')


We'd usually consume this API by serializing the JSON string to a Python =dict=.

#+begin_src python :session stock-session :results output :exports both
def get_tsla_price(stock_json_data: str) -> float:
    return float(json.loads(stock_json_data)["TSLA"]["price"])

print(get_tsla_price(stock_data))
#+end_src

#+results:
: 1000.0


This is alright, but remembering that the =price= field is a string can get tedious. Let's try and do better by defining the type of this JSON structure.

#+begin_src python :session stock-session :results output :exports both
from typing import Dict

def stocks_to_dict(stock_json_data: str) -> Dict[str, Dict[str, float]]:
    return json.loads(stock_json_data)

pprint(stocks_to_dict(stock_data))
#+end_src

#+results:
: {'AAPL': {'price': '400.00'},
:  'AMZN': {'price': '3000.00'},
:  'TSLA': {'price': '1000.00'}}


Now a static type-checker like =mypy= can assume that =stock_data["TSLA"]["price"]= is a =float=.

What if the API changes, and the =get_stocks= method also includes the company name and the percent change (I'm not a stock market expert so this might not be the correct term) in each stock JSON object?

#+begin_src python :session stock-session :results output :exports both
def get_stocks() -> str:
    """
    API method returning some JSON data
    """

    return json.dumps(
        {
            "TSLA": {
                "name": "Tesla, Inc.",
                "price": "1000.00",
                "percent_change": "+2.03%"
            },
            "AMZN": {
                "name": "Amazon.com, Inc.",
                "price": "3000.00",
                "percent_change": "-1.01%"
            },
            "AAPL": {
                "name": "Apple Inc.",
                "price": "400.00",
                "percent_change": "-1.51%"
            }
        }
    )

stock_data = get_stocks()

pprint(stock_data)
#+end_src

#+results:
: ('{"TSLA": {"name": "Tesla, Inc.", "price": "1000.00", "percent_change": '
:  '"+2.03%"}, "AMZN": {"name": "Amazon.com, Inc.", "price": "3000.00", '
:  '"percent_change": "-1.01%"}, "AAPL": {"name": "Apple Inc.", "price": '
:  '"400.00", "percent_change": "-1.51%"}}')


What does the type signature for the serialized =dict= even look like? We wouldn't want to keep the percent change as a string because that would be painful to work with.

This is my best guess but it's still not great.

#+begin_src python :session stock-session :results output :exports both
from typing import Dict, Union


def stocks_to_dict(stock_json_data: str) -> Dict[str, Dict[str, Union[float, str]]]:
    return json.loads(stock_json_data)


pprint(stocks_to_dict(stock_data))
#+end_src

#+results:
: {'AAPL': {'name': 'Apple Inc.', 'percent_change': '-1.51%', 'price': '400.00'},
:  'AMZN': {'name': 'Amazon.com, Inc.',
:           'percent_change': '-1.01%',
:           'price': '3000.00'},
:  'TSLA': {'name': 'Tesla, Inc.',
:           'percent_change': '+2.03%',
:           'price': '1000.00'}}


Most static typecheckers for Python will not complain that this =dict= still doesn't reflect the type of the function. Let's add some type conversions:

#+begin_src python :session stock-session :results output :exports both
from typing import Dict, Union


def stocks_to_dict(stock_json_data: str) -> Dict[str, Dict[str, Union[float, str]]]:
    stocks_dict = json.loads(stock_json_data)
    for symbol in stocks_dict.keys():
        stocks_dict[symbol]["price"] = float(stocks_dict[symbol]["price"])
    return stocks_dict


stocks_dict = stocks_to_dict(stock_data)
pprint(stocks_dict)
print(isinstance(stocks_dict["TSLA"]["price"], float))
#+end_src

#+results:
: {'AAPL': {'name': 'Apple Inc.', 'percent_change': '-1.51%', 'price': 400.0},
:  'AMZN': {'name': 'Amazon.com, Inc.',
:           'percent_change': '-1.01%',
:           'price': 3000.0},
:  'TSLA': {'name': 'Tesla, Inc.', 'percent_change': '+2.03%', 'price': 1000.0}}
: True

** Dynamically adding types

This works, but I'm lazy and don't want to write a specialized =x_to_dict= function for every single API method. I want something like a dynamically type-safe C =struct=---a data-structure that automatically serializes a =dict= with the correct type conversions. Another benefit of this =struct= is that it provides some basic documentation for what kinds of fields the API returns and their types. Dictionaries are still great and definitely have their place in Python programs, but in my opinion, an object called =Stocks= is a lot more descriptive and amenable to refactoring than =Dict[str, Dict[str, Union[float, str]]]=.

Here's an example of some of the functionality that I want:

#+begin_src python
stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)  # -> nice representation of the object
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+RESULTS:

Notice how the =price= and =percent_change= attributes will automatically get converted to =floats=.

Let's take a stab at implementing this with a regular class:

#+begin_src python :session stock-session :results output :exports both
def percent_to_float(percent: str) -> float:
    """
    Converts a percentage string to a float.

    e.g. percent_to_float("+1.01%") -> 0.0101
    e.g. percent_to_float("-22.22%") -> -0.2222
    """

    neg = -1 if percent[0] == "-" else 1
    return neg * float(percent[1:-1]) / 100


class Stocks:
   def __init__(self, *args, **kwargs):
       for symbol, info in kwargs.items():
           # e.g. sets self.TSLA to an empty object
           setattr(self, symbol, type("", (), {})())
           # e.g. sets self.TSLA.name to "Tesla, Inc."
           setattr(getattr(self, symbol), "name", info["name"])
           # e.g. sets self.TSLA.price to 1000.0
           setattr(getattr(self, symbol), "price", float(info["price"]))
           # # e.g. sets self.AMZN.percent_change to -0.0101
           setattr(getattr(self, symbol), "percent_change",
                   percent_to_float(info["percent_change"]))


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)  # -> nice representation of the object
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+results:
: <__main__. object at 0x10ddcc5d0>
: 1000.0
: 0.0203
: -0.0101
: Apple Inc.


This works pretty well! We've used simple metaprogramming to dynamically create class attributes at run-time, all with the correct types! The only problem is that we'd have to add a =__repr__= method to each dynamically-created object to get a nice representation of =stocks.TSLA= when printed. Remember, I'm lazy so this is clearly too much work.

** Type-safety with dataclasses

Remember that this is Python and there's usually a simple answer to most problems in the standard library. Turns out that =NamedTuples= and =dataclasses= both do the trick.

#+begin_src python :session stock-session :results output :exports both
from dataclasses import dataclass


@dataclass
class StockInfo:
    name: str
    price: float
    percent_change: float

    def __post_init__(self):
        self.price = float(self.price)
        self.percent_change = percent_to_float(self.percent_change)


print(StockInfo(**json.loads(stock_data)["TSLA"]))
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)


That was easy! Now we can simplify the =Stock= class to use these =StockInfo= objects.

#+begin_src python :session stock-session :results output :exports both
class Stocks:
   def __init__(self, *args, **kwargs):
       for symbol, info in kwargs.items():
           # e.g. sets self.TSLA to StockInfo object
           setattr(self, symbol, StockInfo(**info))


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)  # -> nice representation of the object
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)
: 1000.0
: 0.0203
: -0.0101
: Apple Inc.


As an added bonus, printing out =stocks.TSLA= gives us a nice representation of the =StockInfo= object, where before it would print out the raw Python object which isn't that helpful (of course, it's easy enough to add a =__repr__= method but that's too much work).

What happens if we try and update the stock?

#+begin_src python :session stock-session :results output :exports both
stocks.TSLA.name = "SpaceX, Inc."
print(stocks.TSLA)
#+end_src

#+results:
: StockInfo(name='SpaceX, Inc.', price=1000.0, percent_change=0.0203)


This isn't good. I want these objects to be immutable which will prevent a whole class of potential errors.

Turns out that =dataclasses= can be immutable with a quick modification to the decorator. That should do the trick?

#+begin_src python :session stock-session :results output :exports both
@dataclass(frozen=True)
class StockInfo:
    name: str
    price: float
    percent_change: float

    def __post_init__(self):
        self.price = float(self.price)
        self.percent_change = percent_to_float(self.percent_change)


print(StockInfo(**json.loads(stock_data)["TSLA"]))
#+end_src

#+results:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-DECY0g", line 12, in <module>
:     print(StockInfo(**json.loads(stock_data)["TSLA"]))
:   File "<string>", line 6, in __init__
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-DECY0g", line 8, in __post_init__
:     self.price = float(self.price)
:   File "<string>", line 4, in __setattr__
: dataclasses.FrozenInstanceError: cannot assign to field 'price'


Looks like the frozen property gets enforced immediately after the =dataclass= gets initialized, so there's no way to change the class instance variables after they're set.

There's a workaround where you can use =super().__setattr__= to bypass the restrictions on calling =setattr= directly because of the =frozen= property. [[https://stackoverflow.com/a/54119384/7432268][(relevant StackOverflow post)]]

#+begin_src python :session stock-session :results output :exports both
@dataclass(frozen=True)
class StockInfo:
    name: str
    price: float
    percent_change: float

    def __post_init__(self):
        super().__setattr__("price", float(self.price))
        super().__setattr__("percent_change", percent_to_float(self.percent_change))


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)

stocks.TSLA.name = "SpaceX, Inc."  # raises an error
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-wfC3n6", line 15, in <module>
:     stocks.TSLA.name = "SpaceX, Inc."  # raises an error
:   File "<string>", line 4, in __setattr__
: dataclasses.FrozenInstanceError: cannot assign to field 'name'

#+begin_src python :session stock-session :exports none
DCStockInfo = StockInfo
#+end_src

#+RESULTS:
: None

Looks like this is working properly.

** Type-safety with NamedTuples

If you don't want to use =dataclasses=, a =NamedTuple= works just as well. =NamedTuples= are immutable by default. We want to do the type conversions before the object is actually initialized using =__new__= because once the =NamedTuple= is created, it's immutable.

#+begin_src python :session stock-session :results output :exports both
from typing import NamedTuple


class StockInfo(NamedTuple):
    name: str
    price: float
    percent_change: float

    def __new__(cls, *args, **kwargs):
        kwargs["price"] = float(kwargs["price"])
        kwargs["percent_change"] = percent_to_float(kwargs["percent_change"])
        return super().__new__(cls, *args, **kwargs)


print(StockInfo(**json.loads(stock_data)["TSLA"]))
#+end_src

#+results:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-Gv1AH2", line 3, in <module>
:     class StockInfo(NamedTuple):
:   File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/typing.py", line 1386, in __new__
:     raise AttributeError("Cannot overwrite NamedTuple attribute " + key)
: AttributeError: Cannot overwrite NamedTuple attribute __new__


Turns out we can't modify the =__new__= method directly to convert the types, but it's possible to hack around this via sub-classing.

#+begin_src python :session stock-session :results output :exports both
from typing import NamedTuple


class _BaseStockInfo(NamedTuple):
    name: str
    price: float
    percent_change: float


class StockInfo(_BaseStockInfo):
    def __new__(cls, *args, **kwargs):
        kwargs["price"] = float(kwargs["price"])
        kwargs["percent_change"] = percent_to_float(kwargs["percent_change"])
        return super().__new__(cls, *args, **kwargs)


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)
stocks.TSLA.name = "SpaceX, Inc."  # raises an error
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-CHqjcX", line 18, in <module>
:     stocks.TSLA.name = "SpaceX, Inc."  # raises an error
: AttributeError: can't set attribute

Looks like it's working properly.

Let's just do a quick check to make sure everything works:

#+begin_src python :session stock-session :results output :exports both
stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+results:
: 1000.0
: 0.0203
: -0.0101
: Apple Inc.

#+begin_src python :session stock-session :exports none
NTStockInfo = StockInfo
#+end_src

#+RESULTS:
: None

Now we have a nice strongly-typed wrapper object for our previously stringly-typed JSON data!

** Dataclass vs NamedTuple

*** Unpacking

What if we want to unpack the =StockInfo= object for multiple-assignment?

This is easy with =NamedTuples= since they work just like regular tuples.

#+begin_src python :session stock-session :results output :exports both
tsla = NTStockInfo(**json.loads(stock_data)["TSLA"])
print("TSLA values: ", *tsla, sep=" | ")
name, _, percent_change = tsla
print(f"percent change for {name} stock is {percent_change}")
#+END_SRC

#+RESULTS:
: TSLA values:  | Tesla, Inc. | 1000.0 | 0.0203
: percent change for Tesla, Inc. stock is 0.0203

The same can't be said for a =dataclass=.

#+begin_src python :session stock-session :results output :exports both
tsla = DCStockInfo(**json.loads(stock_data)["TSLA"])
name, _, percent_change = tsla
print(f"percent change for {name} stock is {percent_change}")
#+END_SRC

#+RESULTS:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-dlN3nO", line 2, in <module>
:     name, _, percent_change = tsla
: TypeError: cannot unpack non-iterable StockInfo object

We can work around this by using the =dataclasses.astuple= function, but it's not as intuitive.

#+begin_src python :session stock-session :results output :exports both
import dataclasses

tsla = DCStockInfo(**json.loads(stock_data)["TSLA"])
print("TSLA values: ", *dataclasses.astuple(tsla), sep=" | ")
name, _, percent_change = dataclasses.astuple(tsla)
print(f"percent change for {name} stock is {percent_change}")
#+END_SRC

#+RESULTS:
: TSLA values:  | Tesla, Inc. | 1000.0 | 0.0203
: percent change for Tesla, Inc. stock is 0.0203

*** Serializing to JSON

Since we're dealing with APIs, it's useful to quickly be able to serialize an object to JSON with the correct types.

#+begin_src python :session stock-session :results output :exports both
tsla = NTStockInfo(**json.loads(stock_data)["TSLA"])

# the _asdict() method converts a NamedTuple to a mapping type
pprint(json.dumps(tsla._asdict()))
#+END_SRC

#+RESULTS:
: '{"name": "Tesla, Inc.", "price": 1000.0, "percent_change": 0.0203}'

#+begin_src python :session stock-session :results output :exports both
import dataclasses

tsla = DCStockInfo(**json.loads(stock_data)["TSLA"])
pprint(json.dumps(dataclasses.asdict(tsla)))
#+END_SRC

#+RESULTS:
: '{"name": "Tesla, Inc.", "price": 1000.0, "percent_change": 0.0203}'

Both approaches work equally well in this case.

*** Documentation

The =dataclass= implementation is, in my opinion, simpler to implement and has nicer built-in documentation via =help(StockInfo)=.

#+BEGIN_SRC
Help on class StockInfo in module __main__:

class StockInfo(builtins.object)
 |  StockInfo(name: str, price: float, percent_change: float) -> None
#+END_SRC

Since our =NamedTuple= implementation is a sub-class, we have to scroll down a bit to find the attributes of the class in the =help= output, and the type annotations are hidden away as an =OrderedDict= in the =_fields= attribute.

#+BEGIN_SRC
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from _BaseStockInfo:
 |
 |  name
 |      Alias for field number 0
 |
 |  price
 |      Alias for field number 1
 |
 |  percent_change
 |      Alias for field number 2
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from _BaseStockInfo:
 |
 |  __annotations__ = OrderedDict([('name', <class 'str'>), ('price', ... ...
 |
 |  _field_defaults = {}
 |
 |  _field_types = OrderedDict([('name', <class 'str'>),
#+END_SRC



* DONE Three Completely Different Approaches to the FizzBuzz Problem :programming:python:OCaml:lisp:
CLOSED: [2020-03-11 Mon 22:49]
:PROPERTIES:
:EXPORT_FILE_NAME: fizzbuzz_approaches
:END:

Here's a solution to the classic infamous FizzBuzz problem in Python:

#+BEGIN_SRC python :results output :exports both
for i in range(1, 31):
    if i % 15 == 0:
        print("FizzBuzz")
    elif i % 3 == 0:
        print("Fizz")
    elif i % 5 == 0:
        print("Buzz")
    else:
        print(i)
#+END_SRC

#+RESULTS:
#+begin_example
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz
16
17
Fizz
19
Buzz
Fizz
22
23
Fizz
Buzz
26
Fizz
28
29
FizzBuzz
#+end_example

This program is really simple and is probably the most common approach. You just
need to understand how =if= statements work and you're good to go.

We can take this up a notch by using type-driven exhaustive pattern-matching so
that our programming language can actually tell us if we've made a mistake in
our implementation. Here's version 2 of the FizzBuzz program using the OCaml
programming language:

#+BEGIN_SRC ocaml :exports both
open Base

let () =
  for i = 1 to 30 do
    match Int.rem i 3, Int.rem i 5 with
    | 0, 0 -> Stdio.print_endline "FizzBuzz"
    | 0, _ -> Stdio.print_endline "Fizz"
    | _, 0 -> Stdio.print_endline "Buzz"
    | _, _ -> Stdio.printf "%d\n" i
  done
#+END_SRC

#+RESULTS:
#+begin_example
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz
16
17
Fizz
19
Buzz
Fizz
22
23
Fizz
Buzz
26
Fizz
28
29
FizzBuzz
#+end_example

Notice the =match= expression right after the =for= loop. OCaml has a really
powerful type system that can catch some tricky edge cases in our logic at
compile time. The function =Int.rem= is just like modulo in other languages (I'm
using the =Base= alternate standard library for OCaml---the default language
comes with a =mod= operator). All the =match= expression in the code above is
doing is saying: "If i mod 3 is 0 and i mod 5 is 0, then print FizzBuzz, else if
i mod 3 is 0 and i mod 5 is anything, then print Fizz, else if i mod 3 is
anything and i mod 5 is 0, then print Buzz, else print i if both are anything".

That looks an awful lot like a standard =if= statement to me. The real advantage
comes when you forget to include a case:

#+BEGIN_SRC ocaml :exports both
open Base

let () =
  for i = 1 to 30 do
    match Int.rem i 3, Int.rem i 5 with
    | 0, 0 -> Stdio.print_endline "FizzBuzz"
    | 0, _ -> Stdio.print_endline "Fizz"
    | _, 0 -> Stdio.print_endline "Buzz"
    (* | _, _ -> Stdio.printf "%d\n" i <-- commented out *)
  done
#+END_SRC

#+RESULTS:
#+begin_example
Characters 45-207:
  ....match Int.rem i 3, Int.rem i 5 with
      | 0, 0 -> Stdio.print_endline "FizzBuzz"
      | 0, _ -> Stdio.print_endline "Fizz"
      | _, 0 -> Stdio.print_endline "Buzz"
Warning 8: this pattern-matching is not exhaustive.
Here is an example of a case that is not matched:
(1, 1)
Exception: Match_failure ("//toplevel//", 228, 4).
Raised at file "//toplevel//", line 231, characters 14-40
Called from file "toplevel/toploop.ml", line 180, characters 17-56
#+end_example

This is really cool---OCaml's compiler knows when the =match= statement doesn't
cover all the possible cases and will even give you an example of a case that
wasn't met! Once we include that last case, the program will successfully
compile. Depending how you structure your pattern matching, the compiler will
sometimes even tell you if you've used redundant or incorrect cases. It's a
killer feature and I wish more languages had it. Exhaustive pattern matching
like this is usually unique to strongly typed functional programming languages,
although Rust has also adopted this feature and I'm sure others will follow.

Now for the third and wildest approach to solving the FizzBuzz problem---this
time with Clojure. Clojure is a Lisp dialect that emphasizes functional
programming and immutable data structures. This language also happens to have
great support for lazy sequences---a feature that this particular FizzBuzz
program uses heavily.

A lazy sequence is not evaluated immediately---instead, it delays its evaluation
until it is needed by another function.

To illustrate this, here's the documentation for the =cycle= function in
Clojure:

#+BEGIN_SRC clojure :results output :exports both :eval never-export
(doc cycle)
#+END_SRC

#+RESULTS:
: -------------------------
: clojure.core/cycle
: ([coll])
:   Returns a lazy (infinite!) sequence of repetitions of the items in coll.

How do you use these so-called infinite sequences without using up all the
memory in your computer? The key to using lazy sequences is that these functions
are not evaluated until they are needed by another function. So running this:

#+BEGIN_SRC clojure
(cycle '("Fizz" "Buzz"))
#+END_SRC

would just hang the Clojure session because it's waiting to be evaluated. Let's
fix that by taking some values from this infinite sequence.

#+BEGIN_SRC clojure :exports both :eval never-export
(take 10 (cycle '("Fizz" "Buzz")))
#+END_SRC

#+RESULTS:
| Fizz | Buzz | Fizz | Buzz | Fizz | Buzz | Fizz | Buzz | Fizz | Buzz |

Now we can write a completely different FizzBuzz implementation leveraging the
power of these lazy sequences. I modified the example from [[http://www.petecorey.com/blog/2018/07/09/golfing-for-fizzbuzz-in-clojure-and-elixir/][this blog post]] so the
output would match my Python and OCaml programs.

#+BEGIN_SRC clojure :results output :exports both :eval never-export
(doseq
    [x
     (->>
      (map list
           (range 31)
           (cycle ["Fizz" "" ""])
           (cycle ["Buzz" "" "" "" ""]))
      (rest)
      (map (fn [lst]
             (let [i (first lst)]
               (if (or (= 0 (mod i 3)) (= 0 (mod i 5)))
                 (apply str (concat (rest lst)))
                 (apply str (concat lst)))))))]
  (println x))
#+END_SRC

#+RESULTS:
#+begin_example
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz
16
17
Fizz
19
Buzz
Fizz
22
23
Fizz
Buzz
26
Fizz
28
29
FizzBuzz
#+end_example

The four lines of code below is the heart of the program. It uses the =range=
function to assign numbers to the first elements of the lists and then uses the
two =cycle= functions to assign either the empty string, Fizz, or Buzz to the
second and third elements of the list respectively. It's a really neat
declarative way of implementing FizzBuzz and my mind was completely blown when I
understood what the program really does.

#+BEGIN_SRC clojure :exports both :eval never-export
(map list
     (range 31)
     (cycle ["Fizz" "" ""])
     (cycle ["Buzz" "" "" "" ""]))
#+END_SRC

#+RESULTS:
|  0 | Fizz | Buzz |
|  1 |      |      |
|  2 |      |      |
|  3 | Fizz |      |
|  4 |      |      |
|  5 |      | Buzz |
|  6 | Fizz |      |
|  7 |      |      |
|  8 |      |      |
|  9 | Fizz |      |
| 10 |      | Buzz |
| 11 |      |      |
| 12 | Fizz |      |
| 13 |      |      |
| 14 |      |      |
| 15 | Fizz | Buzz |
| 16 |      |      |
| 17 |      |      |
| 18 | Fizz |      |
| 19 |      |      |
| 20 |      | Buzz |
| 21 | Fizz |      |
| 22 |      |      |
| 23 |      |      |
| 24 | Fizz |      |
| 25 |      | Buzz |
| 26 |      |      |
| 27 | Fizz |      |
| 28 |      |      |
| 29 |      |      |
| 30 | Fizz | Buzz |

I never knew FizzBuzz could be solved in so many different ways and it's a neat
little problem to illustrate the strengths and styles of different programming
languages: Python is great for writing legible imperative code that's simple yet
expressive. OCaml is great for writing safe strongly typed code with exhaustive
compiler checks when you need them. Clojure is great for writing highly dynamic
functional code which uses lots of abstractions that makes working with data
much easier.


* DONE Remote Linux Process Hacking through SSH :programming:lisp:linux:
CLOSED: [2020-03-09 Mon 22:10]
:PROPERTIES:
:EXPORT_FILE_NAME: remote_process_hacking
:END:

There's this really cool [[https://www.youtube.com/playlist?list=PLBgJcoaU2hl-JnoVOzjYB5qk_PfYjPm-I][process hacking series]] on YouTube by Keist Zenon. He
uses the programming language Common Lisp to interact with processes on his
Linux machine. I tried following the tutorial on my Mac, but macOS does not have
the same =ptrace= commands and system call interfaces as Linux so this did not
work out. However, I have VirtualBox set up on my Mac with a Debian VM which I
use whenever I need Linux.

Here's the idea: is it possible to hack processes on my Linux VM from Emacs on
my Mac? I found out that it's not only possible, but it's actually surprisingly
easy.

** Configuring the Virtual Machine
# :PROPERTIES:
# :HEADER-ARGS:sh: :dir /ssh:debian-box:/home/samarth/cl-ptrace
# :END:

First you'll need to set up a Bridged Adapter on your VirtualBox VM to allow
your host machine to connect to it via SSH. [[https://www.youtube.com/watch?v=ErzhbUusgdI][This YouTube tutorial]] was pretty
helpful. You'll just have to change how you enable the SSH service on your Linux
VM---I'm on Debian so I had to run the command

#+BEGIN_SRC sh :exports both :eval never-export
systemctl status ssh | cat | grep active
#+END_SRC

#+RESULTS:
: Active: active (running) since Fri 2020-03-13 18:24:14 EDT; 33s ago

to see if SSH was enabled.

To attach and manipulate this process, we need to use the =ptrace= function. You
can see the documentation for it with the command =man 2 ptrace= (2 stands for
the second section of the manual, since we want the C system call function for
=ptrace= instead of the general UNIX command). We could use C for process
hacking, but it's a lot nicer to use an interactive language like Lisp. Plus,
it's possible to interact with a remote Lisp REPL from your host machine's local
Emacs instance through SSH. Common Lisp is pretty amazing---I don't know if many
other programming languages have these features.

Clone [[https://github.com/k-stz/cl-ptrace][Keist's GitHub repo]] to your VM to get his Common Lisp library for process
hacking with =ptrace=. The code here is essentially the same as the tutorial,
except you might have to remove the line that says

#+BEGIN_SRC common-lisp
(:file "cl-ptrace/async-functions")
#+END_SRC

since that file doesn't exist in the repo for some reason. Install your Common
Lisp implementation of choice (I use =sbcl= since it's well-supported on most
platforms) and follow the instructions on the [[https://www.quicklisp.org/beta/][Quicklisp website]] to install
Quicklisp. Quicklisp is the unofficial package manager for Common Lisp.

Once you've successfully installed Quicklisp, you need to set up a Lisp REPL on
the remote VM so it can talk to your local Emacs editor. Quit out of your =sbcl=
repl and run it as root. We need Lisp to run as root since the =ptrace= system
calls need root access.

#+BEGIN_SRC sh
sudo sbcl
#+END_SRC

In his tutorial, Kaiste avoided this problem by running Emacs as root since he
was hacking processes from the same machine. However, we don't want to do this
since running Emacs as root can be dangerous, plus we are trying to hack
processes on our /remote/ machine from our /local (host)/ Emacs editor, so
running Emacs locally as root wouldn't really be useful.

Use Quicklisp to load/install =ASDF= and =slynk=, and then create a =slynk=
server on port 4006. You can use the default port 4005 if it's open.

#+BEGIN_SRC common-lisp
(ql:quickload :asdf)
(ql:quickload :slynk)
(slynk:create-server :port 4006)
#+END_SRC

If you get stuck, follow the instructions in [[https://joaotavora.github.io/sly/#Setting-up-the-Lisp-image][the SLY manual]], but I think
Quicklisp makes this process a bit easier.

Now fire up a new terminal and get your VM's ip address. On Debian, the command
is

#+BEGIN_SRC sh :eval never-export
hostname -I
#+END_SRC

#+RESULTS:
: 192.168.1.4

After that, SSH into your VM from your /host/ machine to create an SSH tunnel
that we'll take advantage of later.

#+BEGIN_SRC sh
ssh -L4006:localhost:4006 <username>@<ip-address>
#+END_SRC

Change =4006= to the port that =slynk= is using to run your Lisp server, and
change the =<username>= and =<ip-address>= fields. Remember to run this command
from your host machine, not the VM.

Once your SSH tunnel is set up, follow the instructions in section 8.1.3 of the
SLY manual (linked above) to configure Emacs to translate filenames between the
remote and host machines. Make sure you have TRAMP installed and working in
Emacs. Now you can connect to your VM from your host machine's Emacs using
TRAMP. =C-x C-f /ssh:<username>@<ip-address>= should do the trick. Now you can
navigate to the =cl-ptrace= repo.

The setup is pretty much over: now we can start hacking. Compile the =spam.c=
file in the =cl-ptrace= repo on your VM into the executable =spam= and run it.

#+BEGIN_SRC sh
gcc spam.c -o spam
./spam
#+END_SRC

We want to get the process id (=pid=) of this =spam= program so we can interact
with it. To do this, run the command

#+NAME: spam-pid
#+BEGIN_SRC sh :exports both :eval never-export
ps -a | grep spam | awk '{ print $1 }'
#+END_SRC

#+RESULTS: spam-pid
: 1543

We can then display information about the process with =top=. You can get a
nicer output by using the =htop= program.

#+BEGIN_SRC sh :var PID=spam-pid
top -p $PID
#+END_SRC

We can even limit the output of =top= to just get the CPU usage. The =sed=
commands are just for making the output nicer.

#+BEGIN_SRC sh :var PID=spam-pid :exports both :eval never-export
top -p $PID -n 2 -b | grep Cpu | sed 's/\:/\: /' | sed 's/us,.*/ /'
#+END_SRC

#+RESULTS:
| %Cpu(s): |  53.6 |
| %Cpu(s): | 100.0 |

Notice that the =spam= program is taking up over 90% of the CPU since it's an
infinite =while= loop in a single-threaded process.

** Hacking in Emacs

Next, switch back to Emacs (on the host machine) and make sure you're in the
remote =cl-ptrace= repo via TRAMP. We want to connect to the remote Lisp server
from Emacs, so run the command =M-x sly-connect=, keep the default host as
=localhost=, and change the port to the =slynk= server port.

Now you have a local Lisp REPL that is connected to your VM via the SSH tunnel
we created earlier. Load the file =cl-ptrace.asd= with the command =M-x
sly-load-file=. The file is on the remote VM, but this isn't a problem because
TRAMP should be configured to handle the remote filenames (we did this earlier).
This should load the file into the =sly= REPL. Then run =(asdf:load-system
"cl-ptrace")= to load the =cl-ptrace= library into the REPL, and run
=(in-package :cl-ptrace)= to start using the library.

Make sure that you're root by running the function =(am-i-root?)=. It should
return =T=. Now you've successfully created a mechanism to hack remote processes
from your local machine using Common Lisp and Emacs. Go ahead and follow along
with the rest of Kaiste's videos---they're amazing.

* Interactive OCaml Development :OCaml:programming:
CLOSED: [2020-03-08 Sun 22:06]
:PROPERTIES:
:EXPORT_FILE_NAME: interactive_ocaml_development
:END:

Interactive development features are mostly found in dynamically-typed
interpreted programming languages like Python or JavaScript. While OCaml is a
statically-typed compiled language, it is still possible to program in an
interactive style using a REPL. However, OCaml will never be quite as flexible
and interactive as something like Lisp because of its greatest feature: the
strong static type system.

** Testing functions using the REPL

One of the nicest features of OCaml is that is has both a byte-code compiler
(=ocamlc=) and a native-code compiler (=ocamlopt=). This means that you can
develop programs in an interactive, [[http://www.paulgraham.com/progbot.html][bottom-up]] style using the REPL. Bottom-up
development is a technique most-often leveraged by Lisp programmers in which you
can write a single function, compile it and send it to the REPL, and then test
that function interactively in the REPL. OCaml's fast bytecode compiler makes it
possible to use this technique that is usually unique to Lisps and interpreted
languages.

*** Sending code to the REPL in Emacs
I'll describe the process for interactive development using Emacs which is my
text editor of choice. Similar techniques should exist for other editors such as
VS Code or Vim.

OCaml's REPL is called =utop= and it has a lot of nice features that make it
well-suited for interactive development. If you're using Emacs, you can send
your OCaml code to =utop= to be evaluated. Here's an example of using =utop= to
test a single function.

#+BEGIN_SRC ocaml
open Base

let sum_list list = List.fold ~f:( + ) ~init:0 list
#+END_SRC

To send this code to =utop=, highlight it and press =C-x C-r= (or =M-x
utop-eval-region RET=). You can even send an entire buffer to =utop= by pressing
=C-c C-b= via the function =utop-eval-buffer=. If you use the =dune= build
system and configure Emacs appropriately (instructions on how to do this are in
the [[https://github.com/ocaml-community/utop#main-setup][utop documentation]]), a dialog will pop up saying: "utop command line: opam
config exec -- dune utop . -- -emacs". Press =RET= to evaluate the code.

You might have seen a message saying "Error: unbound module Base". This code
uses [[https://opensource.janestreet.com/base/][Jane Street's Base alternative standard library]] which makes things a bit
more complicated, since =utop= does not know about Base by default.

To solve this, create a new file in the same directory called =.ocamlinit=.
=utop= reads this file before starting and executes the commands specified. You
just need to include a single line to load the Base library into =utop=:

#+BEGIN_SRC ocaml
#require "base";;
#+END_SRC

Now try the previous steps again to load the =sum_list= function into =utop=. If
this still doesn't work, make sure your =opam= environment is set up correctly
by running the command =opam switch= in a terminal and following the
instructions.

Once everything is working, go ahead and test the function in the REPL by
running =sum_list [1; 2; 3];;= (the double semicolons at the end of the line are
important because =utop= uses them to mark the end of an expression). If you
want to make changes to the function, simply switch back to the OCaml buffer,
edit the code, and send it back to =utop=.

*** Working with multiple files in the REPL

The technique I described above works great within a single file, but things get
complicated once you send code from multiple files to the same =utop= instance.
For example, say you made the =sum_list= function within a file called
=test.ml= and sent that code to =utop=. Now you want to use =Test.sum_list=
within another file, so you create a new file called =use_test.ml= which
implements a new function:

#+BEGIN_SRC ocaml
let double_sum_list list = (Test.sum_list list) * 2
#+END_SRC

Now when you go to send this new function to =utop=, you run into an error:
"Error: Unbound module Test".

Here's the full sample =utop= session:

#+BEGIN_SRC
utop[0]> open Base

let sum_list list = List.fold ~f:( + ) ~init:0 list
;;
val sum_list : int list -> int = <fun>
utop[1]> sum_list [1; 2; 3];;
- : int = 6
utop[2]> let double_sum_list list = (Test.sum_list list) * 2
;;

Error: Unbound module Test
#+END_SRC

Since OCaml isn't really made to be an interactive programming language, there
isn't a clean solution for this problem as far as I'm aware. However, you can
hack around this using the same =.ocamlinit= file that I mentioned before.

Kill =utop= and modify the =.ocamlinit= file to look like this:

#+BEGIN_SRC ocaml
#require "base";;
#mod_use "test.ml";;
#+END_SRC

The =#mod_use= function tells =utop= to import the given file into the REPL as a
module. This is important because it lets us call =sum_list= as =Test.sum_list=.
=#mod_use= essentially wraps up the functions from the file into a module and
sends that module to be evaluated in the REPL, which is basically how the OCaml
compiler treats OCaml files. We don't want to change our development style to
work with the REPL since =utop= is configurable enough.

There is one caveat with this approach: you have to edit =.ocamlinit= and
restart =utop= whenever you create a new file. If you switch files (say you were
sending code from =use_test.ml= to the REPL but now want to work with
=test.ml=), you have to restart =utop= each time to ensure that it has the most
up-to-date version of all your files/modules. This is a bit of a pain and I'm
not sure if there's a solution to this problem given OCaml's static nature.

** Pretty-printing

A major part of interactive development is seeing the results of functions in
the REPL. Since OCaml has a strong type system without dynamic dispatch, you can
only print strings---this means that you have to write functions to convert your
user-defined types (which are everywhere in idiomatic OCaml code) to strings
each time you want to print them. This is a pain, but luckily there's an elegant
solution: [[https://github.com/ocaml-ppx/ppx_deriving#plugin-show][ppx]].

=ppx= is a syntax extension to OCaml which acts as a macro that automatically
generates code to pretty-print a custom type (=ppx_deriving.show=), generate
equality functions (=ppx_deriving.eq=), etc.

To pretty-print custom types annotated with =[@@deriving show]= in =utop=, you'll need to
once again modify the =.ocamlinit= file and add the following line:

#+BEGIN_SRC ocaml
#install_printer Module.pp;;
#+END_SRC

where =Module= is the name of the module which has the corresponding =pp=
function. Here's an example of one such module that pretty-prints a custom
hash-table with the =Depths= module, where =type t=... =[@@deriving show]= refers
to the =Resolver.t= type:

#+BEGIN_SRC ocaml
module Depths = struct
  type t = (string, int) Hashtbl.t

  let pp ppf values =
    Caml.Format.open_hovbox 1;
    Caml.Format.print_cut ();
    if Hashtbl.length values = 0
    then Caml.Format.fprintf ppf "@[<hov 2>{}@]"
    else (
      Caml.Format.fprintf ppf "@[<hov 1>{@ @]";
      Hashtbl.iteri values ~f:(fun ~key ~data ->
          Caml.Format.fprintf ppf "@[<hov 2>%s: %d,@ @]" key data);
      Caml.Format.fprintf ppf "@[<hov 1>}@]");
    Caml.Format.close_box ()
  ;;
end

type t =
  { statements : Parser.statement list
  ; scopes : Scopes.t
  ; depths : Depths.t
  ; parsed_statements : Parser.statement list
  }
[@@deriving show]
#+END_SRC

Here are the corresponding lines in =.ocamlinit= which tell =utop= which types
to pretty-print (the above code is from a file called =resolver.ml=):

#+BEGIN_SRC ocaml
#install_printer Resolver.pp;;
#install_printer Resolver.Depths.pp;;
#+END_SRC

Now =utop= knows to call the respective =pp= function whenever it needs to print
type information for the corresponding module. I needed to write the custom
=Depths.pp= function by hand since =ppx_deriving.show= is not powerful enough to
work for all custom types. This is one drawback of strong static type systems.

** Tracing function execution

Say you want to now debug the =resolve= function in your =Resolver= module, but
the return value of =resolve= is of type =Resolver.t=. If you didn't have the
=[@@deriving show]= =ppx= annotation on =type t= and didn't write the custom
=Scopes.pp= and =Depths.pp= functions, this would be part of the output of
tracing a call to =Resolver.resolve= in =utop= (I cut off the rest of the output
since it wasn't important):

#+BEGIN_SRC ocaml
utop[1]> #trace Resolver.resolve;;
Resolver.resolve is now traced.
utop[2]> Scanner.make_scanner "var x = 1; { var y = 2; }"
|> Scanner.scan_tokens
|> Parser.make_parser
|> Parser.parse
|> Resolver.make_resolver
|> Resolver.resolve;;
Resolver.resolve <--
  {Resolver.statements =
    [Parser.VarDeclaration
      {Parser.name =
        {Scanner.token_type = Scanner.Identifier; lexeme = "x";
         literal = Value.LoxNil; line = 1};
       init =
        Parser.Literal
         {Parser.token =
           {Scanner.token_type = Scanner.Number; lexeme = "1";
            literal = Value.LoxNumber 1.; line = 1};
          value = Value.LoxNumber 1.}};
     Parser.Block
      [Parser.VarDeclaration
        {Parser.name =
          {Scanner.token_type = Scanner.Identifier; lexeme = "y";
           literal = Value.LoxNil; line = 1};
         init =
          Parser.Literal
           {Parser.token =
             {Scanner.token_type = Scanner.Number; lexeme = "2";
              literal = Value.LoxNumber 2.; line = 1};
            value = Value.LoxNumber 2.}}]];
   scopes = <abstr>; depths = <abstr>;
#+END_SRC

Notice this last line: =scopes = <abstr>; depths = <abstr>;=. The =<abstr>=
value indicates that OCaml does not know how to print values of the =Scopes.t=
or =Depths.t= type since there are no dedicated =pp= functions for those types.

Once I added the =[@@deriving show]= annotation back to =type t=, wrote the
=Scopes.pp= and =Depths.pp= functions, and added the relevant =#install_printer=
lines to =.ocamlinit=, this was the full output of the same trace to
=Resolver.resolve=:

#+BEGIN_SRC ocaml
utop[1]> #trace Resolver.resolve;;
Resolver.resolve is now traced.
utop[2]> Scanner.make_scanner "var x = 1; { var y = 2; }"
|> Scanner.scan_tokens
|> Parser.make_parser
|> Parser.parse
|> Resolver.make_resolver
|> Resolver.resolve;;
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "1"; literal = (Value.Value.LoxNumber 1.); line = 1 };
             value = (Value.Value.LoxNumber 1.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "1"; literal = (Value.Value.LoxNumber 1.); line = 1 };
             value = (Value.Value.LoxNumber 1.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                 line = 1 };
               value = (Value.Value.LoxNumber 2.) })
          })
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = { y: declared, }; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = { y: declared, }; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = { y: declared, }; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
- : Resolver.t =
{ Resolver.Resolver.statements =
  [(Parser.Parser.Expression
      (Parser.Parser.Literal
         { Parser.Parser.token =
           { Scanner.Scanner.token_type = Scanner.Scanner.Number;
             lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
           value = (Value.Value.LoxNumber 2.) }))
    ];
  scopes = {}; depths = {};
  parsed_statements =
  [(Parser.Parser.VarDeclaration
      { Parser.Parser.name =
        { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
          lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
        init =
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "1"; literal = (Value.Value.LoxNumber 1.); line = 1 };
             value = (Value.Value.LoxNumber 1.) })
        });
    (Parser.Parser.Block
       [(Parser.Parser.VarDeclaration
           { Parser.Parser.name =
             { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
               lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
             init =
             (Parser.Parser.Literal
                { Parser.Parser.token =
                  { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                    lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                    line = 1 };
                  value = (Value.Value.LoxNumber 2.) })
             })
         ])
    ]
  }
utop[8]>
#+END_SRC

Notice how =utop= now knows how to print the =Scopes.t= and =Depths.t= types,
like =scopes = { y: declared, }; depths = {};=, instead of just =scopes =
<abstr>; depths = <abstr>;=. This technique is incredibly useful for debugging
by tracing functions in the REPL and using the REPL interactively in general.

I hope this overview of interactive OCaml development with =utop= was useful.
Even though OCaml is a language that has an uncompromisingly strict static type
system, it's still possible to get some of the useful interactive features
of more dynamic languages like Lisp through a configurable plugin-based REPL and
syntax extensions that help minimize boilerplate. Sometimes you really can have
your cake and eat it too!

* Footnotes
* COMMENT Local Variables                          :ARCHIVE:
# Local Variables:
# eval: (org-hugo-auto-export-mode)
# End:
