#+TITLE: Samarth's Blog
#+HUGO_BASE_DIR: ../
#+OPTIONS:  ^:nil
#+HUGO_SECTION: posts/
#+HUGO_AUTO_SET_LASTMOD: t
#+STARTUP: logdone

<<<<<<< HEAD
* TODO Categorizing Programming Languages                                :PL:
:PROPERTIES:
:EXPORT_FILE_NAME: categorizing-programming-languages
:END:

There are many different ways to categorize programming languages: dynamic vs static, strict vs lazy, OO vs functional, etc. There's already plenty of information about this on the Internet.

I think there's a different way to categorize programming languages based more on the language's underlying philosophy rather than the technical details of its specification or implementation. In this case, there are two types of languages: "hacker" languages and "secure" languages. These are completely made-up terms but I think they provide a useful frame of reference.

** "Hacker" Languages

"Hacker" languages are for programmers who like to get things done. Instead of forcing the programmer to adapt to the limitations of the language, the programmer can adapt the language around the program. The underlying philosophy of "hacker" languages is [[https://www.jwz.org/doc/worse-is-better.html][Worse is Better]]. For example, "hacker" langauges usually have weak and/or dynamic typing which lets the programmer write a program without having to worry about satisfying the type-checker. There are many programs that are completely valid and bug-free, but cannot compile in some statically-typed languages due to the limited expressiveness of the type-checker. Hackers are willing to trade the computer-assisted verification of some parts of their program for the ability to write their program in any way they want. Just because a program is dynamic does not mean it is full of bugs---programmers who prefer "hacker" languages will usually catch bugs through extensive testing rather than from compiler errors. Either that, or they just prefer to hack things together for throwaway programs/scripts and don't really care about minor bugs if they happen to crop up. The latter is more of a [[https://xkcd.com/1428/]["move fast and break things"]] approach.

Programmers do not have to use dynamic features in these langauges, but a program written in a "hacker" language will not look out-of-place if it is overly dynamic---it's all about giving programmers the freedom to write programs however they want. I don't think it's possible for a strongly- and statically-typed language to be considered a "hacker" language.

Let's look at some examples of popular "hacker" languages:

*** C

C is statically-typed, yet it's a great example of a flexible procedural programming language. Features such as type casts and =void= pointers allow programmers to subvert the type system in order to gain flexibility at run-time. For example, the [[https://linux.die.net/man/3/qsort][qsort]] function in the C standard library takes a comparison function with two =void*= arguments, allowing the function to work with any type (as long as the types are casted appropriately). This comes with the downside that the compiler in many cases cannot verify that the program passes the correct types to =qsort=, and the program may crash at run-time because of this. C also has primitive but powerful preprocessor macros that allow programmers to reduce boilerplate. It is possible to write bug-free and memory-safe programs written in C---most of the modern computing infrastructure is written in this language---but it is difficult and often requires discipline and good tools. Sometimes programmers really need the flexibility of a language like C---for example, it is extremely difficult to write a [[https://way-cooler.org/blog/2019/04/29/rewriting-way-cooler-in-c.html][compositor]] in safe Rust.

*** JavaScript

Just as /C/ is the /lingua franca/ of UNIX systems, JavaScript is the /lingua franca/ of the Web. I believe that this is for a good reason---both languages are extremely flexible. Brendan Eich (in)famously hacked together a working prototype of JavaScript (initially called Mocha) in just ten days. JS, like C, is weakly-typed, but it is also dynamically-typed and object-oriented. This makes it more difficult for the language to verify that certain parts of a program are correct, like passing a number to a method that only takes strings; however, it means that the programmer can leverage the dynamic object system to create [[https://svelte.dev/][sophisticated programs]] with little code. JavaScript was implemented as a small scripting language for websites and most likely was not designed to scale beyond a few thousand lines. With its poor support for detecting errors early and tendency to allow minor mistakes to [[https://javascriptwtf.com/][escape undetected]], it is possible for websites with JS scripts to run (albeit not correctly) without crashing, which sometimes can be a nice feature to have.

*** Clojure

Clojure is a strongly- and dynamically-typed functional programming language. Saying that it's popular might be a bit of a stretch, but oh well... Although programmers often consider functional languages to be more theory-oriented and less suitable for getting things done (although thankfully this sentiment seems to be changing), Clojure is heavily inspired by Lisp which means it's naturally a [[http://paulgraham.com/avg.html][great fit for hackers]]. Clojurians embrace [[https://clojure.org/about/dynamic][dynamic language features]] like metaprogramming, REPLs, and multiple-dispatch while rejecting the limitations imposed by static type systems, preferring to catch bugs by using [[https://clojure.org/about/functional_programming#_immutable_data_structures][immutable data structures]], [[https://lispcast.com/nil-punning/][nil-punning]], and [[https://clojure.org/about/spec][generative testing]] instead. Its dynamicism makes Clojure a fantastic choice for quick prototyping, and the idiomatic use of immutability and [[https://clojure.org/about/runtime_polymorphism][polymorphism]] throughout the language makes it easier to extend the code in the future. However, this dynamicism comes at a cost---a Clojure program can run slower than the equivalent Java program due to Clojure's lack of type information at run-time, and sometimes Clojure code needs [[https://clojure.org/reference/java_interop#typehints][type hints]] to achieve comparable performance. While Clojure encourages immutability, it does not forbid using mutable state, giving programmers the option to use whichever approach makes sense. In this sense, Clojure is pragmatic and does not claim to be a "pure" functional language like Haskell.

** "Secure" Languages

*** Rust

*** TypeScript

*** Scala
=======
* DONE The Role of Open Source in Addressing Inequality         :open_source:
CLOSED: [2021-02-26 Fri 23:00]
:PROPERTIES:
:EXPORT_FILE_NAME: open_source_inequality
:END:

This is my second blog post for the UVA class LPPS 4720.

Inequality manifests itself in many different ways, but I will only address one of these in this post: access to information. The 21st century, the so-called "Information Age", is a time where connection to the Internet along with basic literacy enables an unprecedented number of people to freely participate in the "[[https://waitbutwhy.com/2017/04/neuralink.html#part1][Human Colossus]]". However, even with the Internet, the abuse of strict intellectual property laws can restrict free access to information and perpetuate inequality. As said in page 217 of the [[http://hdr.undp.org/sites/default/files/hdr2019.pdf][UN 2019 Human Development Report]], "economic institutions and laws created in the 20th century to manage industrialization in developed economies may need to be reconsidered in the 21st century".

In a 2013 /New York Times/ [[https://opinionator.blogs.nytimes.com/2013/07/14/how-intellectual-property-reinforces-inequality/][opinion page]], Joseph Stiglitz argues that 'some of the most iniquitous aspects of inequality creation within our economic system are a result of "rent-seeking": profits, and inequality, generated by manipulating social or political conditions to get a larger share of the economic pie, rather than increasing the size of that pie'. The intellectual property system in the US (which inspired many similar systems around the world) encourages people and companies to restrict access to certain information. One example of this (which Stiglitz thoroughly discussed) is the issue of Myriad trying to patent two genes, a naturally occurring phenomenon, and using these patents to massively inflate the price of their gene tests which prevented many people from affording them. This is not only morally reprehensible and contributes to inequality, it is also now illegal thanks to a Supreme Court ruling.

One can argue that publicly traded companies are responsible for the welfare of their shareholders and therefore seek to maximize short-term gains, which is exactly what the current intellectual property system prioritizes. However, if a company wants to succeed in the long-term, it needs to ensure that it can generate value, which is best achieved through sustained innovation. According to the above cited UN report, "in the last few decades a higher concentration of patent ownership, echoing the broader pattern of market concentration, has contributed to declines in knowledge diffusion and business dynamism". The diffusion of and equal access to knowledge contributes to a healthy economy which in turn benefits businesses. Corporate success does not have to be a zero-sum game---it is possible to create a system that promotes equality and contributes to the success of public corporations.

One possible solution to this problem is an Open Source approach. In the case of Myriad, sharing their genetic findings instead of filing for patents would have prevented a 30% drop in their share price after the Supreme Court ruling and incentivized the company to produce more ground-breaking innovations, further increasing its value and share price. In fact, as Stiglitz argues, "Myriadâ€™s own discovery---like any in science---used technologies and ideas that were developed by others", and "[had] that prior knowledge not been publicly available, Myriad could not have done what it did". Myriad's abuse of the patent system, if allowed to continue, would have stagnated innovation and prevented the advancement of science---which is the very justification for the patent system's existence in the first place. The advancement of science and technology is a major reason why equality has advanced so far in the past few decades. I'm not arguing that patents are universally bad, just that they are more likely to be abused in the name of short-term profit, discouraging innovation and perpetuating inequality. If [[https://www.justice.gov/atr/page/file/1119131/download][history]] [[https://www.courtlistener.com/opinion/2266659/united-states-v-american-telephone-telegraph-co/][is]] [[http://neconomides.stern.nyu.edu/networks/Microsoft_Antitrust.final.pdf][any]] [[https://www.bloomberg.com/news/articles/2020-10-29/eu-court-limits-antitrust-regulators-data-demands-from-facebook][indication]], monopolies rarely survive for long in modern capitalistic societies.

* DONE The Role of Open Source in Innovation and Product Development :open_source:
SCHEDULED: <2021-02-11 Thu>
:PROPERTIES:
:EXPORT_FILE_NAME: open_source_innovation_product_development
:END:

This is my first blog post for the UVA class LPPS 4720.

While Intellectual Property (IP) has been a useful tool in the past to foster entrepreneurship, it has many underlying issues. An Open Source philosophy is a great alternative to IP which solves many of its issues, but still is not a silver bullet. To understand the advantages of Open Source when applied to innovation and product development, it is important to first understand IP. According to the [[https://www.wipo.int/about-ip/en/][World Intellectual Property Organization]], "Intellectual property (IP) refers to creations of the mind, such as inventions; literary and artistic works; designs; and symbols, names and images used in commerce." The primary purpose of Intellectual Property is to encourage innovation by providing financial incentives and/or competitive advantages to those who create new products or ideas---this is done via Copyright, Patents, Trademarks, Trade Secrets, etc. In essence, it allows entrepreneurs to protect their work by preventing others from profiting off it.

The Open Source philosophy offers a different approach. Instead of incentivizing innovation through extrinsic motivation like money, it relies on intrinsically motivated innovators to make products for fun and release the designs to the public. Open Source does not mean that these products are not copyrighted---the creator of the product can choose whether to keep a copyright or to release their work into the public domain, or sometimes the license is beyond the creator's control and is dictated by which other products the product is using or extending (especially in the case of copyleft licenses). Examples of Open Source products include [[https://www.arduino.cc/][Arduino]] microchips, [[https://www.opendesk.cc/designs][furniture designs]], [[https://www.openprosthetics.org/][prosthetics]], and the world's most widely-used [[https://www.linuxfoundation.org/][operating system]].

Benefits of IP:
- Over 800,000 patents are granted every year around the world, providing invaluable information on the status of competitors and allowing companies to save money on R&D costs [[[https://www.wipo.int/export/sites/www/sme/en/documents/pdf/ip_innovation_development.pdf][1]]].
- VC firms and other investors often require that businesses register for patents in order to protect their ideas and help ensure its profitability [[[https://www.wipo.int/export/sites/www/sme/en/documents/pdf/ip_innovation_development.pdf][1]]].
- Trademarks can help distinguish products from similar competitors which also helps with marketing. They also make it easier and less risky for brands to develop products for new markets [[[https://www.wipo.int/export/sites/www/sme/en/documents/pdf/ip_innovation_development.pdf][1]]].

Drawbacks of IP:
- IP law can be complicated to navigate and expensive to enforce, with basic patent filing fees adding up to over $2,000 according to the [[https://www.uspto.gov/learning-and-resources/fees-and-payment/uspto-fee-schedule][USPTO]].
- [[https://en.wikipedia.org/wiki/Patent_troll]["Patent trolls"]] can obtain the rights to patents and then enforce them far beyond their original scope, stifling innovation by making it difficult to avoid infringing on the patents' protections. In the United States, this can lead to costly legal fees because of the American rule.
- The economics of IP-based product development can discourage companies from taking risks and spending time and money to develop a unique and innovative product [[[http://www.adciv.org/Open_collaborative_design#Why_is_this_a_good_thing.3F][2]]].

Benefits of Open Source:
- Open designs make it easy for anyone to extend another person or company's ideas, encouraging collaborative innovation. These types of innovations are often driven by passion instead of profit (intrinsic as opposed to extrinsic motivation), leading to higher quality products [[[http://www.adciv.org/Open_collaborative_design#Why_is_this_a_good_thing.3F][2]]].
- The collaborative nature of open source products gives people a sense of community where the consumers of a product can also directly contribute back to it.
- [[https://www.gnu.org/copyleft/][Copyleft]] applies copyright principles to Open Source, making it difficult for proprietary (non-open) products to take advantage of work that others have been doing for free and have released into the public domain under an open license. It also encourages the viral spread of Open Source.

Drawbacks of Open Source:
- While it is still possible to make money off Open Source, it is sometimes more difficult to profit off an open product.
- Companies can take advantage of products using non-copyleft open licenses (such as BSD, MIT, etc.) by integrating them into their own proprietary products. However, this is not an issue for some Open Source developers and is often a conscious choice to increase adoption.
- Companies will often avoid using copyleft products because of the [[https://lwn.net/Articles/117972/][potential legal issues]] which can hurt their widespread adoption.

These days, there is little reason to keep making proprietary software in my opinion---the benefits of the Open Source development model far outweigh the minor potential losses in revenue. Companies like [[https://www.redhat.com/en/about/company][Red Hat]] and [[https://www.elastic.co/about/free-and-open][ElasticSearch]] thrive on a primarily Open Source business model and are still profitable. There is an important distinction between [[https://docs.freebsd.org/en/articles/bsdl-gpl/article.html][BSD-style]] Open Source and [[https://www.gnu.org/philosophy/free-software-even-more-important.html][GNU-style]] Free Software which I won't go into in this post, but I think the BSD license model works well for enterprise software since it allows companies to develop proprietary extensions to their core Open Source technologies if needed. Open Source can still play an important role in the hardware space since companies can make money by selling physical products, whereas it's more difficult to charge money for Open Source software.

While I certainly think that Open Source is a great idea and should be the default choice for most new products, there are also important benefits for using traditional IP in the product development process. In some cases it is easier to justify using traditional IP to protect certain products, especially when starting a venture with high up-front costs that requires VC, Angel, or other forms of investment. For most other types of ventures, entrepreneurs should strongly consider using an Open Source model.

Last modified on 2/19/2021.
>>>>>>> 0dcec6b28964ab4d2171ffdefb158b79a9de4bb1

* TODO Teaching University CS from First Principles                      :PL:
:PROPERTIES:
:EXPORT_FILE_NAME: university-cs-from-first-principles
:END:

/"Computer Science is no more about computers than astronomy is about telescopes"/ - Edsger Dijkstra

This is a really long post so here's the TLDR:
  - I think that CS curriculums should be structured around [[https://www.wikipedia.com/wiki/First_principle][First Principles]] to ensure that most students who graduate have a rock-solid base of knowledge without any major gaps. There are only two ways to achieve this:
    - Lambda Calculus: Start from logic and math, and use a language based on the Lambda Calculus to work your way up the stack (this is better in my opinion). Then switch to using C-like languages based on the Turing Machine in later courses. This does not mean that an intro course should even mention Lambda Calculus! It's just a useful frame of reference.
    - Turing Machine: Start from von Neumann architecture and machine code and work your way up the stack using a language based on the Turing Machine. Then switch to the Lambda Calculus approach in later courses.
  - CS curriculums should offer two introductory courses: one for potential majors and another for students who want to learn some basic programming.
    - The programming course for non-majors should be taught in Python (or any other *popular* language suitable for beginners) and is basically what most intro CS courses are like today. This course should focus on practical applications of programming like automating computer tasks by writing scripts.
    - The course for majors should be taught in a way that completely evens the playing field for those who have some previous programming experience and those who have none. It should also encourage students to program using concepts they have learned from math and logic (First Principles) instead of teaching students how to think like a machine. I argue that Racket is a good language for teaching such a course.
  - Universities want to produce graduates who can get good-paying jobs or go to graduate school.
    - CS graduates who have extremely stong fundamentals are more valuable for the workplace and will find it easier to improve and/or maintain codebases. They will also have an easier time learning new languages and technologies.
    - Graduate schools want students with strong fundamentals in theoretical computer science who know how to apply theory to solve interesting problems and write papers that will get published.

I'm a fourth-year undergrad CS student at the University of Virginia. UVA has a decently-rated CS curriculum geared towards producing capable software engineers. Based on my experience, the CS department here tends to focus on more "practical" software engineering and less on theoretical computer science.

For reference, UVA has two different CS degrees---BA and BS. I'm a BA which means I don't have to take some courses like OS and Theory of Computation but instead am required to take some interdisciplinary courses in the College of Arts and Sciences that somewhat relate to computing. I will not be focusing on those interdisciplinary courses in this post. The only required BS course that I did not end up taking is Advanced Software Development (it focused on web development in Django, and I already had some experience with that in an internship). BA students cannot take Digital Logic Design so that one doesn't count.

Here are the courses I have taken so far:

| Semester | Course Name                   | Course Number |
|----------+-------------------------------+---------------|
|        1 | *Introduction to Programming*   | CS 1111       |
|        2 | *Discrete Mathematics*          | CS 2102       |
|        2 | *Software Development Methods*  | CS 2110       |
|        3 | *Program & Data Representation* | CS 2150       |
|        4 | *Theory of Computation*         | CS 3102       |
|        4 | *Algorithms*                    | CS 4102       |
|        5 | *Computer Architecture*         | CS 3330       |
|        5 | Programming Languages         | CS 4610       |
|        6 | *Operating Systems*             | CS 4414       |
|        7 | Compilers                     | CS 4620       |
|        7 | Artificial Intelligence       | CS 4710       |
|        8 | Software Logic                | CS 4501       |
|        8 | Compilers                     | CS 6620       |

The required courses (for a BS) that I have taken are in bold.

With the exception of my 8th (current) semester, this is pretty representative of the types of courses that a typical CS student at UVA will take. Most people end up taking Advanced Software Development and Databases at some point but tend to avoid theory-heavy courses like Programming Languages and Compilers. UVA's CS curriculum has changed in the past couple years but the core content is mostly the same, so my arguments still apply to the new curriculum.

** My Problem with Intro CS Courses and a Possible Solution

Before I say anything else, I want to make it clear that I am in no way criticizing individual CS professors. They have all been incredibly helpful and really want students to succeed. I just disagree with some of the topics that the curriculum emphasizes and the way that the curriculum is fundamentally structured (the new CS course structure at UVA does not solve these problems but is a step in the right direction).

I believe that to truly understand something, you need to learn it from [[https://www.wikiwand.com/en/First_principle][First Principles]]. No math class would ever consider teaching multiplication before addition. Likewise, there are really only two ways to teach an introductory CS course from First Principles
    - Lambda Calculus (thinking like a mathematician): Start from logic and math, and use a language based on the Lambda Calculus to work your way up the stack. Then switch to using C-like languages based on the Turing Machine in later courses and work your way up the stack from Machine Code.
    - Turing Machine (thinking like a computer): Start from von Neumann architecture and machine code and work your way up the stack using a language based on the Turing Machine. Then switch to using Lisp- or ML-like languages based on the Lambda Calculus in later courses.

For the record, I don't recommend introducing Lambda Calculus or Turing Machines this early. They are just useful ways to categorize programming languages and ways of thinking.

[[https://jamesclear.com/first-principles][First Principles]] is an important framework for thinking---without it, SpaceX would never have made a relatively cheap rocket that not only is capable of sending astronauts to the International Space Station, but can autonomously land in order to be reused for future flights. The same thing applies to Computer Science---we will be doomed to never make progress unless we have a strong understanding of the fundamentals of computing.

The first CS class that students take is "Introduction to Programming" which is taught in Python. Python is a fine language, but I don't think that it's a good choice for an introductory CS course for prospective CS majors.

*** The Problem with Imperative Programming Languages

Let's look at how Python handles variables. To someone who has never seen a computer program before, what do you think they would say this program does?

#+begin_src python
x = 2
x = x + 1
#+end_src

I'd be willing to bet that most students would say that =x = x + 1= is impossible. How can =x= be equal to itself plus one? That doesn't make any sense! In math, a variable is something that is bound to a value---you can't change it later on. In CS jargon, this is called immutability.

Brown University uses the Racket programming language for its intro course. Racket makes setting variables explicit so it's an improvement over Python, although its syntax is unusual:

#+begin_src scheme
(let [[x 2]]
  (set! x (+ x 1)))
#+end_src

Prolog, a logic programming language, is one of the few languages that actually follows the math.

#+begin_src prolog
?- X = 2, X = X + 1.
false.
#+end_src

=== is /equality/ in Prolog, not assignment. The Prolog program is trying to answer the question "is it true that when =X= is equal to 2, =X= is equal to =X= plus 1?" Naturally, the answer is =false=---such a question doesn't even make sense in a language like Prolog.

Learning any kind of imperative language like Python, Java, C, etc. as a beginner will not be intuitive. For someone to fully understand what Python is doing when it executes =x = x + 1=, they will need to understand references, de-referencing variables, l-values, r-values, expressions, and statements. The =x= on the left-hand-side of the equals sign is the l-value which means that it's referring to a variable---a location in memory that can store a value, not a variable in the mathematical sense which is a binding from a name to a value. The =x= on the right-hand-side of the equals sign is an r-value which means that it's the value in memory that the variable =x= is storing (the number 2). Those two Python =x= variables are not the same, even though they look the same. On the other hand, the Prolog program is pretty much executable math and logic---=X= is =X= regardless of which side its on.

OCaml, a functional language in the ML family, makes all of the steps in the Python program more explicit:

#+begin_src ocaml
let x = ref 1 in
x := !x + 1
#+end_src

Here we bind =x= to a reference containing the value 1. Incrementing =x= involves de-referencing the reference to =x= via the =!= operator to get its value and assigning =x= to its old value plus one. Binding values uses === and assignment uses =:==. In my opinion, this is much more clear (even though de-referencing with =!= still looks a little weird to me since I'm so used to C-like languages). Furthermore, you don't even have to know what a statement is---everything in OCaml is an expression that returns something. In this case, the entire block of code is an expression that returns a value of the =unit= type, which is basically the equivalent of =void= in C-like languages.

However, even introducing the concept of references this early doesn't make much sense to me. To actually understand what a reference is, you need to understand how computers use memory---a topic that UVA's CS curriculum does not cover until CS 2150 (or the equivalent low-level programming course taught in C or C++).

Let's go back to the topic of teaching from First Principles. I said there are only two ways to structure an intro CS course this way: bottom-up or top-down. Either way works, but I think it's far easier to justify the top-down approach. Students would probably get bored if all they can do for the first few classes is flip bits and write Assembly. With a top-down approach, they can write high-level code that does interesting things within a few short days.

Python is supposed to be a high-level language though! That's why so many CS departments start with Python instead of C, right? The problem is not that Python is "high-level", but that it forces the programmer to think like a machine.

Let's go back to the earlier example:

#+begin_src python
x = 1
x = x + 1
#+end_src

To understand what this does, you have to think about it in the following steps:
 - Declare the variable =x= and set it to 1
 - Add 1 to the value of =x=
 - Set the new value of =x= to be the incremented value

This feels pretty low-level to me. You have to go line-by-line and execute the insructions in your head statement-by-statement. There's relatively little mathematical or logical thinking involved.

Python, Java, and other such languages have rules whether a type is implicitly a value or a reference. This makes them harder for beginners to learn because it's another case to memorize.

This prints 1 because =x= is an integer, a value type:

#+begin_src python :results output :exports both
def increment(x):
    x = x + 1

n = 1
increment(n)
print(n)
#+end_src

#+RESULTS:
: 1

However, this example prints 2 because =x= is an object, a reference type:

#+begin_src python :results output :exports both
class Num:
    def __init__(self):
        self.val = 1


def increment(x):
    x.val = x.val + 1


n = Num()
increment(n)
print(n.val)
#+end_src

#+RESULTS:
: 2

In C, you have to be explicit whether a type is a value or a reference:

#+begin_src C :includes <stdio.h> :exports both
  void increment(int x) {
      x = x + 1;
  }

  int main() {
      int n = 1;
      increment(n);
      printf("%d\n", n);
  }
#+end_src

#+RESULTS:
: 1

C prints 1 because functions have value semantics unless they explicitly use pointers. This is the C version of the Python code that uses objects:

#+begin_src C :includes <stdio.h> :exports both
  void increment(int *x) {
      *x = *x + 1;
  }

  int main() {
      int n = 1;
      increment(&n);
      printf("%d\n", n);
  }
#+end_src

#+RESULTS:
: 2

Here it prints 2 because =x= is explicitly passed by-reference to the =increment= function. Languages like Python and Java have reference semantics where all non-"primitive" types are implicitly references, just like C pointers.

Learning about this made sense at a surface level during my intro CS course, but it never really clicked until 2 semesters later when I finally learned about pointers in C++. We never learned about pass-by-reference from First Principles.

I think that using languages with implicit reference semantics to teach an introductory CS class is a bad idea if you're trying to adhere to the First Principles approach, but unfortunately, this rules out pretty much every popular programming language except C and C++. However, even C and C++ are not ideal because they force you to think like the machine, and we're trying to stick to high-level math and logic. This means that the only available languages to teach intro CS are functional or logic languages.

*** The Case for Using an Obscure Functional/Logic Language for Intro CS

First, let's address some rebuttals:
 - Students want to learn skills that they can actually use. Python is a useful language and no one cares about obscure languages like Lisp, ML, or Prolog.
   - This is an intro CS course for potential CS majors. No one knows what is or isn't "useful" yet, and if a student has an opinion about this, he or she most likely has too little experience to have a well-founded opinion in the first place. There's still plenty of time later on to learn Python and Java, but a language with an intuitive syntax and semantics (for beginners with no prior exposure to imperative languages) is a great fit for an intro course.
 - Students with previous experience in languages like Python and JavaScript will be at a disadvantage.
   - Yes, this is potentially a good thing because an unfamiliar language will even the playing field and ensure that everyone learns the same material. At the end of the day, this course is about teaching CS fundamentals, not teaching general-purpose programming, and a language like Racket or Prolog excels at this.
 - Students will be turned off by the unfamiliar syntax (especially for Lisps like Racket).
   - Unfamiliar syntax can be a good thing. If taught well, Lisp syntax is extremely simple and can be learned in far less time than supposedly simple languages like Python. It also introduces the concept of data structures early on---your program is itself a list. This will also expose students to a way of thinking about syntax which will help in later courses when they learn languages like C and Python---syntax isn't that important and one of its main uses is to distinguish between different semantics. There are zero corner-cases in Lisp syntax and only a few in Prolog or ML (the programming language family, not Machine Learning), whereas in Python, you have to memorize dozens of [[https://stackoverflow.com/a/33833896][corner-cases]].

Here's an example of a corner-case in Python's syntax that doesn't make sense until you understand the difference between expressions and statements. This difference doesn't exist in a Lisp or ML dialect because everything is an expression.

This doesn't work because =if= is a statement:

#+begin_src python
x = if True:
      1
    else:
      2
#+end_src

An =if= expression looks completely different:

#+begin_src python
x = 1 if True else 2
#+end_src

In Racket, it looks like this---everything in the language is an expression wrapped in either square brackets or parentheses:

#+begin_src scheme
(let [[x (if true 1 2)]]
   ;; use x...
)
#+end_src

Here's another case for teaching a functional language early on: historically imperative languages are slowly getting features that have been in functional languages for decades. This is similar to the time when procedural languages like PHP and Perl got OO features 15-25 years ago, after Java's meteoric rise in popularity.
  - C++: [[https://en.cppreference.com/w/cpp/language/lambda][Lambdas]], [[https://en.cppreference.com/w/cpp/utility/optional][optional types]] (like Haskell's =Maybe= or OCaml's =Option.t=), [[https://en.cppreference.com/w/cpp/language/constraints][concepts]] (similar to Haskell type classes), basic [[https://en.cppreference.com/w/cpp/language/auto][type inference]]
  - Java: [[https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html][Lambdas]], [[https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html][streams]], [[https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html][optional types]], [[https://docs.oracle.com/en/java/javase/14/language/records.html][records]], basic [[https://developer.oracle.com/java/jdk-10-local-variable-type-inference.html][type inference]]
  - PHP: Closures ([[https://nullprogram.com/blog/2019/09/25/][sort of...]])
  - Python: Pattern matching, data classes, optional types

Rust, one of the most popular new imperative languages, has immutable variables by default, [[https://en.wikipedia.org/wiki/Value_semantics][value semantics]], higher-order functions, and proper lexical closures.

Closures and higher-order functions are [[https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures#practical_closures][everywhere]] in JavaScript code, and in 2020 JS is the most or second-most popular programming language in the world.

Universities should teach new ideas, not stick to decades-old "best practices". To get with the times and future-proof their core courses for the next few decades, CS curriculums need to place a greater emphasis on functional and logic programming. If nothing else, students should at least learn about immutability and higher-order functions.

*** A Proposed Syllabus for CS 101

I'll admit that I have zero experience designing syllabi but I'll give this my best shot. Note that this is not language-specific and the topics (in order) will mostly look like this:

- Early CS History: Ada, Turing, Church, etc. This is optional but might help put things into perspective
- Strings, and numbers (all immutable, Unicode should be introduced early)
- Expressions
- Variables (immutable)
- The concept of abstraction (this is crucial to understand because all of CS is just layers of abstraction)
- Abstracting expressions with functions
- Conditional expressions and booleans
- Recursion
- Debugging techniques such as tracing function execution, printing expressions, and stepping through code
- Abstracting functions with higher-order functions
- Lists (singly-linked with =cons= cells)
- Syntax sugar
- Hashmaps and trees (use lists to build these)
- Basic algorithms like searching and sorting
- Final project: apply these techniques to make a game or some other type of interactive GUI
- Optional extra credit assignment: write an interpreter for a simple Scheme dialect (inspired by [[https://mitpress.mit.edu/sites/default/files/sicp/full-text/sicp/book/node76.html][SICP]])

This follows First Principles because students already have an intuitive sense for numbers, expressions, variables, and functions from math. A string is just text. Conditional expressions and booleans are also rooted in math and fundamental logic. I chose to introduce lists after higher-order functions because lists can be [[https://github.com/samarthkishor/lambda-clj/blob/master/src/lambda/data.clj][implemented]] in terms of functions---this goes back to Lambda Calculus. Syntax sugar is a fancy way of explaining substitution---lists represented as nested functions can be "de-sugared" into regular lists like =[1, 2, 3]=.

Teaching recursion early will give students a massive advantage when they start learning about more complex algorithms like BFS and DFS later on. Once recursion is intuitive, control structures like for- and while-loops will be trivial to understand, and can be implemented using recursion.

I also think that CS courses should place a much greater emphasis on debugging since it's an extremely useful skill to quickly find bugs. Professional programmers spend a lot of time debugging and [[https://www.codinginterview.com/amazon-interview][some coding interviews]] even have a dedicated debugging section. This intro course should heavily emphasize using a debugger or print statements to quickly and efficiently diagnoze problems in code.

*** The Case for Racket (a Lisp dialect)

Quick disclaimer: I've never really used Racket myself but have read some second-hand accounts of it and some of the official documentation. I do have experience with Lisps (Clojure, Emacs Lisp, and a bit of Common Lisp), Prolog, and ML (Standard ML and OCaml).

Racket is fork of Scheme which is a dialect of Lisp. In my opinion, Scheme is the second simplest programming language (the simplest is probably Forth, but the two are pretty close). Simple languages are ideal for teaching and avoid a lot of confusion down the line when covering more advanced topics.

One of the major criticisms against teaching Lisp is its weird syntax. I'll admit that Lisp syntax is not ideal for real-world programming for a number of reasons that I won't get into in this post. However, it's great for beginners. Once you get used to the syntax (which only takes around 30 minutes), Lisp allows you to focus on your actual program instead of worrying about trivial things like where to place a comma or semicolon. It also gives you an intuitive sense for lists and trees, since a Lisp program is basically just the program's Abstract Syntax Tree.

MIT used to teach its introductory CS class in Scheme but [[https://www.wisdomandwonder.com/link/2110/why-mit-switched-from-scheme-to-python][switched to Python]] over 10 years ago. Their reasoning was perfectly valid at the time, but a modern Scheme descendant like Racket has plenty of libraries for [[https://docs.racket-lang.org/framework/index.html][GUI]] and [[https://docs.racket-lang.org/quick/][interactive programming]] that will keep students engaged. I also argued above that Python is a poor choice for the intro course of a CS curriculum based on First Principles, even though it has a fantastic library ecosystem. Yes, programming today is mostly gluing existing pieces of software together and keeping legacy code from falling apart, but that's no excuse for choosing not to teach students how software fundamentally works.

Racket has a great IDE called DrRacket with support for interactive programming. Having a REPL, a shell that allows you to interactively execute small snippets of code without having to recompile your whole program, is a crucial feature for any begginer-friendly programming language. DrRacket is easy to install on all major platforms and is easy to use.

As opposed to many other obscure programming languages, Racket has excellent documentation that is geared towards beginners. The error messages are also pretty good. Python has one of the better official documentation stories from what I've seeen, but Racket's official docs are top of the line. Typed Racket (a static typing system for Racket implemented in the language itself) might be more useful than the core dynamic Racket because it will force students to think about types early (which they have to do in dynamically-typed languages anyways).

No one really uses Racket in industry and that's perfectly okay. I don't think that any course after CS 101 should use Racket, but it's great for teaching the fundamentals. [[https://github.com/racket/racket/wiki/Courses-using-Racket][Multiple universities]] use the language so there is plenty of teaching material.

Here are some other potential languages and reasons why they're not as good of a fit:
- Prolog: unpopular option for intro CS but should definitely be taught in a later course, logic programming is too far-removed from imperative... it's easier to switch between functional and imperative languages, not a lot of good documentation
- OCaml: currying by default is confusing and makes it harder to teach, GUI ecosystem is lacking, documentation isn't very good but is improving
- Clojure: the language is fantastic since everything is immutable but you need to know Java in order to read the error messages... this might be improved in the future
- Haskell: lazy evaluation is nice coming from math but it's too far-removed from eagerly-evaluated imperative languages, error messages can be difficult to understand
- Standard ML, Scheme: not a lot of documentation or libraries

** A New Core CS Curriculum Based on First Principles

Partially reproduced from above, this table represents all the required BS courses I have taken. These make up the "core" CS curriculum. I'm also including Programming Languages (which introduces functional and logic programming) because I believe that universities should teach logic programming to every CS major.


| Semester | Course Name                   | Course Number | Language(s)                     |
|----------+-------------------------------+---------------+---------------------------------|
|        1 | *Introduction to Programming*   | CS 1111       | Python                          |
|        2 | *Discrete Mathematics*          | CS 2102       | English or [[https://leanprover.github.io/][Lean]]                 |
|        2 | *Software Development Methods*  | CS 2110       | Java                            |
|        3 | *Program & Data Representation* | CS 2150       | Machine code, x86 Assembly, C++ |
|        4 | *Theory of Computation*         | CS 3102       | Paper & pen, Python or Java     |
|        4 | *Algorithms*                    | CS 4102       | Python or Java                  |
|        5 | *Computer Architecture*         | CS 3330       | x86 Assembly, C, [[https://github.com/woggle/hclrs][HCLRS]]          |
|        5 | Programming Languages         | CS 4610       | OCaml, Prolog                   |
|        6 | *Operating Systems*             | CS 4414       | x86 Assembly, C, C++            |

Assuming a CS major takes the version of Discrete Math with Lean and takes Programming Languages, he or she will end up learning at least 8 different real programming lanugages (yes, Lean counts as a real language): Python, Lean, Java, x86 Assembly, C++, C, OCaml, and Prolog.

Here is my proposed structure:

| Semester | Course Name                      | Course Number | Language(s)                         |
|----------+----------------------------------+---------------+-------------------------------------|
|        1 | *Introduction to Computer Science* | CS 1110       | Racket                              |
|        1 | Introduction to Programming      | CS 1???       | Python                              |
|        2 | *Discrete Mathematics*             | CS 2???       | [[https://leanprover.github.io/][Lean]]                                |
|        2 | *Theory of Computation*            | CS 2???       | English, Racket or Python           |
|        3 | *Computer Architecture*            | CS 3330       | [[https://github.com/woggle/hclrs][HCLRS]], [[https://uva-cs.github.io/pdr/book/ibcm-chapter.pdf][IBCM]], x86 Assembly, Forth(?) |
|        3 | *Data Structures and Algorithms 1* | CS 3???       | C                                   |
|        4 | *Data Structures and Algorithms 2* | CS 3???       | C                                   |
|        5 | *Software Development Methods*     | CS 4???       | Scala 3                             |
|        6 | *Operating Systems*                | CS 4414       | x86 Assembly, C, Rust               |
|        7 | *Programming Languages*            | CS 4610       | Prolog, Scala ([[https://akka.io/][Akka]])                |

With these changes, a CS major will still end up learning at least 8 different lanuages: Racket, Lean, x86 Assembly, Forth, C, Scala, Rust, and Prolog. They can add Python to the list if they choose to take Introduction to Programming. Yes, Scala is not nearly as popular and "useful" as Java, and Python and C++ are notably missing from the list, but I'll address these points later when they come up.

*** Introduction to Programming

This course should pretty much be identical to the current version of [[http://cs1110.cs.virginia.edu/schedule.html][CS 1110]]. It's mainly for students who want some exposure to programming but do not intend on pursuing a degree in CS. If a student enjoys this course and wants to start taking more classes, it may be a little difficult to un-learn some habits from Python, but I don't imagine there will be too much of a barrier-to-entry for the Introduction to Computer Science course (taught in Racket).

*** Discrete Mathematics

The version of this course taught by Professor Sullivan using Lean should be the [[https://github.com/kevinsullivan/cs-dm][default curriculum]]. Since students will already have been exposed to functional programming, there will be no need to spend the first half of the semester teaching those concepts, and the course can spend a lot more time covering set theory, propositional logic, and theorem proving. It is really important that students have a solid intuition for set theory because it is crucial for succeeding in Theory of Computation and understanding how Lean's type system works. Lean's unusual syntax (most likely inspired by ML languages) will seem a lot more approachable and familiar coming from Racket since it is also expression-based. Introducing students to a language with [[https://leanprover.github.io/theorem_proving_in_lean/dependent_type_theory.html][dependent types]] this early might seem a bit extreme, but it's an [[https://mitpress.mit.edu/books/little-typer][intuitive]] approach to static typing which makes less powerful type systems (like the one in C) feel extremely spartan and more approachable in comparison.

This course could follow First Principles by first introducing set theory which will help with understanding Lean's type system. Then comes propositional logic and demonstrating how Lean helps automate writing logical proofs. I think this is how the course is largely structured (minus the type theory) so I don't anticipate much change. The key to making this work is that Lean the system is not the focus of the course---it is just a tool that students use to help them with writing proofs. This avoids having to learn exactly how Lean works under the hood in order to stick to the First Principles approach.

Why is type theory important? Basically no one uses dependent type systems in the real world, and very few even use a language with a [[http://dev.stephendiehl.com/fun/006_hindley_milner.html][Hindley-Milner]] type system. These are true points, but static type systems in many [[https://mypy.readthedocs.io/en/latest/kinds_of_types.html][popular]] [[https://www.typescriptlang.org/docs/handbook/2/types-from-types.html][languages]] are starting to become [[https://openjdk.java.net/jeps/8213076][more]] and [[https://docs.microsoft.com/en-us/dotnet/csharp/pattern-matching][more]] [[https://en.cppreference.com/w/cpp/language/constraints][complex]], to the point where they are basically trying to bolt on a Hindley-Milner or more advanced type system to a type system that was originally far less expressive (or even dynamic in the case of Python's =mypy= tool and TypeScript). The next step from Hindley-Milner is essentially dependent types, so might as well teach it early. I also have some other ulterior motives for this which I will explain in a later section.

*** Theory of Computation

The [[https://www.cs.virginia.edu/~njb2b/cstheory/s2020/schedule.html][current version of this course]] is nearly perfect---I just think that the course should spend a bit more time covering Lambda Calculus (at least 30 minutes for one lecture) and how it led to McCarthy's groundbreaking development of [[http://www-formal.stanford.edu/jmc/recursive.pdf][LISP]], the first high-level programming language. Alan Kay called the original LISP evaluator [[https://queue.acm.org/detail.cfm?id=1039523]["the Maxwell's Equations of software"]].

Theory of Computation follows First Principles because it builds up the essentials of computation from small primitives---boolean logic (NAND gates). Each model of computation grows in expressive power and builds off the previous. In theory, this course should be able to stand alone and does not need any prerequisite material except for basic set theory. The main reason that this is not the introductory CS course is because students will likely get bored and not appreciate the material as much if they have no previous exposure to CS (however, I have no evidence to back this up beyond my own experience).

*** Computer Architecture

This is where things get interesting...

Computer Architecture should come after Theory of Computation because it represents a paradigm shift from the Lambda Calculus (used in Intro to CS and Discrete Mathematics) to the Turing Machine, which is how the vast majority of modern computers work. Theory of Computation extensively covers Turing Machines. In order to stick to First Principles, students must be exposed first to the von Neumann architecture and how the Turing Machine model of computation maps to hardware.

[[https://github.com/woggle/hclrs][HCLRS]] is a useful tool used to teach how CPUs work. Students write a high-level description of the hardware using the HCLRS language which then models the CPU hardware in software. This naturally follows the von Neumann architecture lessons.

From learning how CPUs work, the next step is to learn the machine language that CPUs know how to execute. [[https://uva-cs.github.io/pdr/book/ibcm-chapter.pdf][IBCM]] is a suitable toy machine language for this purpose. From IBCM, the course can then introduce Assembly language (any Assembly language is fine, but it's probably easier to stick to x86 since most students' computers can natively execute it). This is similar to how part of CS 2150 is structured. Another important part of CS 2150 is learning how data is represented in the computer---for example, [[https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF][floating point numbers]], Big vs Little Endianness, etc., and this information should also be included in the Computer Architecture course. Students will already have been exposed to decimal numbers from math and binary from machine code, so this still follows First Principles.

Things like caches, TLBs, etc. can be introduced any point after modeling the CPU hardware. However, it is probably better to learn about these topics after Assembly so students can learn how to write cache-friendly code (which in my opinion is by far the most important part of a Computer Architecture course).

Time permitting, it may also be useful to introduce the Forth prorgamming language, which is a high-level language (honestly, it's more of a programming environment and [[https://cfhcable.dl.sourceforge.net/project/thinking-forth/reprint/rel-1.0/thinking-forth-color.pdf][philosophy]] than a language) that translates almost directly to machine code, so it is highly efficient and [[https://github.com/nornagon/jonesforth/blob/master/jonesforth.S][easy to implement in Assembly]]. Forth is highly extensible, so students can see how a simple bare-bones Forth implementation can be used to create a productive programming environment with [[https://collapseos.org/forth.html][minimal resources]]. In a way, if McCarthy's LISP is the ultimate untyped lambda calculus implementation and ML is the ultimate typed lambda calculus implementation, Forth is the ultimate Turing Machine implementation.

*** Data Structures and Algorithms

Knowledge of data structures and algorithms is crucial to developing good software---this is probably the most important class a CS major can take. Recommending C as the language of choice may seem strange, but I think it makes perfect sense for the following reasons:
  - C is a ([[https://port70.net/~nsz/c/c99/n1256.html#J.2][mostly]]) simple language so students can focus on debugging their algorithms instead of debugging their programming language knowledge.
  - C is an imperative procedural language which makes it relatively close to pseudocode. OOP is largely unnecessary for learning data structures or algorithms---simple =structs= and functions work just fine.
  - C also forces students to think about pointers which is essential in understanding how data structures are implemented. Since it comes with minimal "batteries", students will have to implement most data structures and algorithms themselves which is exactly what you want in a class like this.
  - C is the /lingua franca/ of modern computers and no CS curriculum should consider itself complete without an introduction to C.

Students should have all the necessary knowledge to understand [[https://en.wikipedia.org/wiki/The_C_Programming_Language][K&R]] after finishing Computer Architecture, so the first couple of classes can introduce C and move on to implementing essential data structures like linked lists, trees, hashmaps, sets, queues, stacks, heaps, etc. It will be easy to stick to First Principles as long as students are introduced to pointers before implementing any data structures. A statement is just an expression that evaluates to =void=, loops are just structured jump instructions (or can be implemented using recursion), =structs= are just a bunch of bytes grouped together with a fixed size, arrays are just pointers, and function pointers are similar to first-class functions from Racket and Lean. Perhaps the most important thing to take away from this course is an understanding of Big O complexity classes (both time and space) and how choosing different data structures and algorithms impacts efficiency.

I'm not completely familiar with the new DSA course structure but I doubt many of the topics will need to be changed because of the switch from Java to C. If anything, the course may even become more streamlined because students will not need to worry about classes, inheritance, dynamic dispatch, and other baggage that comes with trying to apply object-oriented programming techniques to data structures and algorithms. I'm not hating on OOP---it's a fantastic and extremely useful paradigm (I even propose keeping a dedicated course to teach it), but it's not the answer to every problem.

The main downside of C is how difficult it is to debug, but students will have to learn how to use a good debugger eventually so might as well start off with =gdb=. Also, while command line tools may seem archaic in 2021, many programmers write code in UNIX-like environments, so knowing how to use the terminal is still necessary. The pain of programming in C (this also applies to C++) will have the added benefit of making higher level languages seem like luxury, and students will likely appreciate the added type- and memory-safety guarantees that languages like Rust provide after experiencing their fair share of segfaults due to de-referencing a null pointer (the [[https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/]["billion dollar mistake"]]).

*** Software Development Methods

I intend this course to be a replacement for CS 2110 (taught in Java). Here are the major goals of the course:
- Teach students how to write software that is (relatively) easy to read, maintain, and scale
- Teach students how to efficiently diagnoze problems in software (this is arguably the more important goal)

If you think about it, software development isn't really a science, so saying that this is a CS course is a bit of a misnomer. There's basically [[https://www.hillelwayne.com/post/reasoning-about-systems/][no research]] that offers conclusive evidence of whether static types are "better" than dynamic types for avoiding bugs, or whether FP is "better" than OOP. That being said, this type of a course is necessary because students will be expected to write maintainable and scalable code in the real world.

I think that teaching students how to choose "the right tool for the job" is the best way to structure a course on software development, but the question is what counts as "right"? It's a difficult question with no correct answer, and explaining my thoughts on the matter would take a while and this post is long enough as it is. As a result, this course should teach a combination of OOP and FP by exposing scenarios where one paradigm clearly fits a problem better than the other, and scenarios where both would be appropriate. In my opinion, Scala is a great language for this because it combines both OOP and FP rather elegantly and does not have a steep learning curve when students already know Racket and Lean.

The trend in 2021 is that companies with large code bases in dynamically-typed languages are realizing that they can sometimes be [[https://slack.engineering/typescript-at-slack/][difficult to maintain]], so statically- and gradually-typed languages are on the rise. This is why I chose a statically typed language for this course, and Scala would also make it easy to port over some of the existing Java content from 2110. Important OOP topics include [[http://www.purl.org/stefan_ram/pub/doc_kay_oop_en][message passing, encapulation, late binding]], inheritance (should be avoided in favor of [[https://reactjs.org/docs/composition-vs-inheritance.html][composition]] in most cases), interfaces, abstract classes, and dynamic dispatch. If students really want, they can look up how these features are [[https://github.com/python/cpython/tree/master/Objects][implemented in an OOP language]], but this is the one case where First Principles doesn't really apply.

Diagnozing problems is another critical skill that CS curriculums should place a much greater emphasis on. Students will have already used debuggers in previous courses, but profiling a program in order to determine performance bottlenecks is a crucial skill that should be a major component of any lecture involving optimization. Profilers are valuable tools, yet I was never taught how to use one in school. Testing is another really important skill, and this course should not only teach unit testing, but also introduce [[https://www.pivotaltracker.com/blog/generative-testing][generative]] and [[https://www.hillelwayne.com/post/contract-examples/][property]] testing. Since the course uses Scala, it can also teach students how to leverage an expressive static type system to [[https://blog.janestreet.com/effective-ml-revisited/]["make illegal states unrepresentable"]].

*** Operating Systems

*** Programming Languages

* DONE Typed APIs in Python with dataclasses and NamedTuples :programming:python:
CLOSED: [2020-08-13 Thu 13:35]
:PROPERTIES:
:EXPORT_FILE_NAME: typed_apis_in_python
:END:

Why would Python programmers ever care about types? While Python doesn't check any types statically (before running the program), it does perform extensive run-time type checking. Checking types at run-time without any implicit casts makes the language strongly-typed and dynamically-typed, as opposed to a language like C which is weakly-typed and statically-typed. This is an important distinction, but I won't go over the differences between strong and weak typing in this post.

Newer versions of Python 3 have support for type annotations which gives the programmer some more information about types. Tools like =mypy= perform some basic static type checking. However, these static type-checkers are not all-powerful and sometimes it's useful to provide some extra type-safety dynamically at run-time.

** The API

Imagine you're writing a Python script that uses a stock market API. The API provides a GET method called =get_stocks= which returns some JSON data containing information about three very specific stocks you're interested in (this is important because we know exactly what data the API method will return and therefore can model it). This is a bit hand-wavy, but the actual API call doesn't matter---we only care about the JSON return value.

#+begin_src python :session stock-session :results output :exports both
import json
from pprint import pprint

def get_stocks() -> str:
    """
    API method returning some JSON data
    """

    return json.dumps(
        {
            "TSLA": {"price": "1000.00"},
            "AMZN": {"price": "3000.00"},
            "AAPL": {"price": "400.00"}
        }
    )


stock_data = get_stocks()
pprint(stock_data)
#+end_src

#+results:
: ('{"TSLA": {"price": "1000.00"}, "AMZN": {"price": "3000.00"}, "AAPL": '
:  '{"price": "400.00"}}')


We'd usually consume this API by serializing the JSON string to a Python =dict=.

#+begin_src python :session stock-session :results output :exports both
def get_tsla_price(stock_json_data: str) -> float:
    return float(json.loads(stock_json_data)["TSLA"]["price"])

print(get_tsla_price(stock_data))
#+end_src

#+results:
: 1000.0


This is alright, but remembering that the =price= field is a string can get tedious. Let's try and do better by defining the type of this JSON structure.

#+begin_src python :session stock-session :results output :exports both
from typing import Dict

def stocks_to_dict(stock_json_data: str) -> Dict[str, Dict[str, float]]:
    return json.loads(stock_json_data)

pprint(stocks_to_dict(stock_data))
#+end_src

#+results:
: {'AAPL': {'price': '400.00'},
:  'AMZN': {'price': '3000.00'},
:  'TSLA': {'price': '1000.00'}}


Now a static type-checker like =mypy= can assume that =stock_data["TSLA"]["price"]= is a =float=.

What if the API changes, and the =get_stocks= method also includes the company name and the percent change (I'm not a stock market expert so this might not be the correct term) in each stock JSON object?

#+begin_src python :session stock-session :results output :exports both
def get_stocks() -> str:
    """
    API method returning some JSON data
    """

    return json.dumps(
        {
            "TSLA": {
                "name": "Tesla, Inc.",
                "price": "1000.00",
                "percent_change": "+2.03%"
            },
            "AMZN": {
                "name": "Amazon.com, Inc.",
                "price": "3000.00",
                "percent_change": "-1.01%"
            },
            "AAPL": {
                "name": "Apple Inc.",
                "price": "400.00",
                "percent_change": "-1.51%"
            }
        }
    )

stock_data = get_stocks()

pprint(stock_data)
#+end_src

#+results:
: ('{"TSLA": {"name": "Tesla, Inc.", "price": "1000.00", "percent_change": '
:  '"+2.03%"}, "AMZN": {"name": "Amazon.com, Inc.", "price": "3000.00", '
:  '"percent_change": "-1.01%"}, "AAPL": {"name": "Apple Inc.", "price": '
:  '"400.00", "percent_change": "-1.51%"}}')


What does the type signature for the serialized =dict= even look like? We wouldn't want to keep the percent change as a string because that would be painful to work with.

This is my best guess but it's still not great.

#+begin_src python :session stock-session :results output :exports both
from typing import Dict, Union


def stocks_to_dict(stock_json_data: str) -> Dict[str, Dict[str, Union[float, str]]]:
    return json.loads(stock_json_data)


pprint(stocks_to_dict(stock_data))
#+end_src

#+results:
: {'AAPL': {'name': 'Apple Inc.', 'percent_change': '-1.51%', 'price': '400.00'},
:  'AMZN': {'name': 'Amazon.com, Inc.',
:           'percent_change': '-1.01%',
:           'price': '3000.00'},
:  'TSLA': {'name': 'Tesla, Inc.',
:           'percent_change': '+2.03%',
:           'price': '1000.00'}}


Most static typecheckers for Python will not complain that this =dict= still doesn't reflect the type of the function. Let's add some type conversions:

#+begin_src python :session stock-session :results output :exports both
from typing import Dict, Union


def stocks_to_dict(stock_json_data: str) -> Dict[str, Dict[str, Union[float, str]]]:
    stocks_dict = json.loads(stock_json_data)
    for symbol in stocks_dict.keys():
        stocks_dict[symbol]["price"] = float(stocks_dict[symbol]["price"])
    return stocks_dict


stocks_dict = stocks_to_dict(stock_data)
pprint(stocks_dict)
print(isinstance(stocks_dict["TSLA"]["price"], float))
#+end_src

#+results:
: {'AAPL': {'name': 'Apple Inc.', 'percent_change': '-1.51%', 'price': 400.0},
:  'AMZN': {'name': 'Amazon.com, Inc.',
:           'percent_change': '-1.01%',
:           'price': 3000.0},
:  'TSLA': {'name': 'Tesla, Inc.', 'percent_change': '+2.03%', 'price': 1000.0}}
: True

** Dynamically adding types

This works, but I'm lazy and don't want to write a specialized =x_to_dict= function for every single API method. I want something like a dynamically type-safe C =struct=---a data-structure that automatically serializes a =dict= with the correct type conversions. Another benefit of this =struct= is that it provides some basic documentation for what kinds of fields the API returns and their types. Dictionaries are still great and definitely have their place in Python programs, but in my opinion, an object called =Stocks= is a lot more descriptive and amenable to refactoring than =Dict[str, Dict[str, Union[float, str]]]=.

Here's an example of some of the functionality that I want:

#+begin_src python
stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)  # -> nice representation of the object
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+RESULTS:

Notice how the =price= and =percent_change= attributes will automatically get converted to =floats=.

Let's take a stab at implementing this with a regular class:

#+begin_src python :session stock-session :results output :exports both
def percent_to_float(percent: str) -> float:
    """
    Converts a percentage string to a float.

    e.g. percent_to_float("+1.01%") -> 0.0101
    e.g. percent_to_float("-22.22%") -> -0.2222
    """

    neg = -1 if percent[0] == "-" else 1
    return neg * float(percent[1:-1]) / 100


class Stocks:
   def __init__(self, *args, **kwargs):
       for symbol, info in kwargs.items():
           # e.g. sets self.TSLA to an empty object
           setattr(self, symbol, type("", (), {})())
           # e.g. sets self.TSLA.name to "Tesla, Inc."
           setattr(getattr(self, symbol), "name", info["name"])
           # e.g. sets self.TSLA.price to 1000.0
           setattr(getattr(self, symbol), "price", float(info["price"]))
           # # e.g. sets self.AMZN.percent_change to -0.0101
           setattr(getattr(self, symbol), "percent_change",
                   percent_to_float(info["percent_change"]))


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)  # -> nice representation of the object
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+results:
: <__main__. object at 0x10ddcc5d0>
: 1000.0
: 0.0203
: -0.0101
: Apple Inc.


This works pretty well! We've used simple metaprogramming to dynamically create class attributes at run-time, all with the correct types! The only problem is that we'd have to add a =__repr__= method to each dynamically-created object to get a nice representation of =stocks.TSLA= when printed. Remember, I'm lazy so this is clearly too much work.

** Type-safety with dataclasses

Remember that this is Python and there's usually a simple answer to most problems in the standard library. Turns out that =NamedTuples= and =dataclasses= both do the trick.

#+begin_src python :session stock-session :results output :exports both
from dataclasses import dataclass


@dataclass
class StockInfo:
    name: str
    price: float
    percent_change: float

    def __post_init__(self):
        self.price = float(self.price)
        self.percent_change = percent_to_float(self.percent_change)


print(StockInfo(**json.loads(stock_data)["TSLA"]))
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)


That was easy! Now we can simplify the =Stock= class to use these =StockInfo= objects.

#+begin_src python :session stock-session :results output :exports both
class Stocks:
   def __init__(self, *args, **kwargs):
       for symbol, info in kwargs.items():
           # e.g. sets self.TSLA to StockInfo object
           setattr(self, symbol, StockInfo(**info))


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)  # -> nice representation of the object
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)
: 1000.0
: 0.0203
: -0.0101
: Apple Inc.


As an added bonus, printing out =stocks.TSLA= gives us a nice representation of the =StockInfo= object, where before it would print out the raw Python object which isn't that helpful (of course, it's easy enough to add a =__repr__= method but that's too much work).

What happens if we try and update the stock?

#+begin_src python :session stock-session :results output :exports both
stocks.TSLA.name = "SpaceX, Inc."
print(stocks.TSLA)
#+end_src

#+results:
: StockInfo(name='SpaceX, Inc.', price=1000.0, percent_change=0.0203)


This isn't good. I want these objects to be immutable which will prevent a whole class of potential errors.

Turns out that =dataclasses= can be immutable with a quick modification to the decorator. That should do the trick?

#+begin_src python :session stock-session :results output :exports both
@dataclass(frozen=True)
class StockInfo:
    name: str
    price: float
    percent_change: float

    def __post_init__(self):
        self.price = float(self.price)
        self.percent_change = percent_to_float(self.percent_change)


print(StockInfo(**json.loads(stock_data)["TSLA"]))
#+end_src

#+results:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-DECY0g", line 12, in <module>
:     print(StockInfo(**json.loads(stock_data)["TSLA"]))
:   File "<string>", line 6, in __init__
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-DECY0g", line 8, in __post_init__
:     self.price = float(self.price)
:   File "<string>", line 4, in __setattr__
: dataclasses.FrozenInstanceError: cannot assign to field 'price'


Looks like the frozen property gets enforced immediately after the =dataclass= gets initialized, so there's no way to change the class instance variables after they're set.

There's a workaround where you can use =super().__setattr__= to bypass the restrictions on calling =setattr= directly because of the =frozen= property. [[https://stackoverflow.com/a/54119384/7432268][(relevant StackOverflow post)]]

#+begin_src python :session stock-session :results output :exports both
@dataclass(frozen=True)
class StockInfo:
    name: str
    price: float
    percent_change: float

    def __post_init__(self):
        super().__setattr__("price", float(self.price))
        super().__setattr__("percent_change", percent_to_float(self.percent_change))


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)

stocks.TSLA.name = "SpaceX, Inc."  # raises an error
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-wfC3n6", line 15, in <module>
:     stocks.TSLA.name = "SpaceX, Inc."  # raises an error
:   File "<string>", line 4, in __setattr__
: dataclasses.FrozenInstanceError: cannot assign to field 'name'

#+begin_src python :session stock-session :exports none
DCStockInfo = StockInfo
#+end_src

#+RESULTS:
: None

Looks like this is working properly.

** Type-safety with NamedTuples

If you don't want to use =dataclasses=, a =NamedTuple= works just as well. =NamedTuples= are immutable by default. We want to do the type conversions before the object is actually initialized using =__new__= because once the =NamedTuple= is created, it's immutable.

#+begin_src python :session stock-session :results output :exports both
from typing import NamedTuple


class StockInfo(NamedTuple):
    name: str
    price: float
    percent_change: float

    def __new__(cls, *args, **kwargs):
        kwargs["price"] = float(kwargs["price"])
        kwargs["percent_change"] = percent_to_float(kwargs["percent_change"])
        return super().__new__(cls, *args, **kwargs)


print(StockInfo(**json.loads(stock_data)["TSLA"]))
#+end_src

#+results:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-Gv1AH2", line 3, in <module>
:     class StockInfo(NamedTuple):
:   File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/typing.py", line 1386, in __new__
:     raise AttributeError("Cannot overwrite NamedTuple attribute " + key)
: AttributeError: Cannot overwrite NamedTuple attribute __new__


Turns out we can't modify the =__new__= method directly to convert the types, but it's possible to hack around this via sub-classing.

#+begin_src python :session stock-session :results output :exports both
from typing import NamedTuple


class _BaseStockInfo(NamedTuple):
    name: str
    price: float
    percent_change: float


class StockInfo(_BaseStockInfo):
    def __new__(cls, *args, **kwargs):
        kwargs["price"] = float(kwargs["price"])
        kwargs["percent_change"] = percent_to_float(kwargs["percent_change"])
        return super().__new__(cls, *args, **kwargs)


stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA)
stocks.TSLA.name = "SpaceX, Inc."  # raises an error
#+end_src

#+results:
: StockInfo(name='Tesla, Inc.', price=1000.0, percent_change=0.0203)
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-CHqjcX", line 18, in <module>
:     stocks.TSLA.name = "SpaceX, Inc."  # raises an error
: AttributeError: can't set attribute

Looks like it's working properly.

Let's just do a quick check to make sure everything works:

#+begin_src python :session stock-session :results output :exports both
stocks = Stocks(**json.loads(stock_data))
print(stocks.TSLA.price)  # -> 1000.0
print(stocks.TSLA.percent_change)  # -> 0.0203
print(stocks.AMZN.percent_change)  # -> -0.0101
print(stocks.AAPL.name)  # -> "Apple Inc."
#+end_src

#+results:
: 1000.0
: 0.0203
: -0.0101
: Apple Inc.

#+begin_src python :session stock-session :exports none
NTStockInfo = StockInfo
#+end_src

#+RESULTS:
: None

Now we have a nice strongly-typed wrapper object for our previously stringly-typed JSON data!

** Dataclass vs NamedTuple

*** Unpacking

What if we want to unpack the =StockInfo= object for multiple-assignment?

This is easy with =NamedTuples= since they work just like regular tuples.

#+begin_src python :session stock-session :results output :exports both
tsla = NTStockInfo(**json.loads(stock_data)["TSLA"])
print("TSLA values: ", *tsla, sep=" | ")
name, _, percent_change = tsla
print(f"percent change for {name} stock is {percent_change}")
#+END_SRC

#+RESULTS:
: TSLA values:  | Tesla, Inc. | 1000.0 | 0.0203
: percent change for Tesla, Inc. stock is 0.0203

The same can't be said for a =dataclass=.

#+begin_src python :session stock-session :results output :exports both
tsla = DCStockInfo(**json.loads(stock_data)["TSLA"])
name, _, percent_change = tsla
print(f"percent change for {name} stock is {percent_change}")
#+END_SRC

#+RESULTS:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/var/folders/9k/rrglbkg540qc7_jb7g6d9l8r0000gn/T/babel-Jeqvjt/python-dlN3nO", line 2, in <module>
:     name, _, percent_change = tsla
: TypeError: cannot unpack non-iterable StockInfo object

We can work around this by using the =dataclasses.astuple= function, but it's not as intuitive.

#+begin_src python :session stock-session :results output :exports both
import dataclasses

tsla = DCStockInfo(**json.loads(stock_data)["TSLA"])
print("TSLA values: ", *dataclasses.astuple(tsla), sep=" | ")
name, _, percent_change = dataclasses.astuple(tsla)
print(f"percent change for {name} stock is {percent_change}")
#+END_SRC

#+RESULTS:
: TSLA values:  | Tesla, Inc. | 1000.0 | 0.0203
: percent change for Tesla, Inc. stock is 0.0203

*** Serializing to JSON

Since we're dealing with APIs, it's useful to quickly be able to serialize an object to JSON with the correct types.

#+begin_src python :session stock-session :results output :exports both
tsla = NTStockInfo(**json.loads(stock_data)["TSLA"])

# the _asdict() method converts a NamedTuple to a mapping type
pprint(json.dumps(tsla._asdict()))
#+END_SRC

#+RESULTS:
: '{"name": "Tesla, Inc.", "price": 1000.0, "percent_change": 0.0203}'

#+begin_src python :session stock-session :results output :exports both
import dataclasses

tsla = DCStockInfo(**json.loads(stock_data)["TSLA"])
pprint(json.dumps(dataclasses.asdict(tsla)))
#+END_SRC

#+RESULTS:
: '{"name": "Tesla, Inc.", "price": 1000.0, "percent_change": 0.0203}'

Both approaches work equally well in this case.

*** Documentation

The =dataclass= implementation is, in my opinion, simpler to implement and has nicer built-in documentation via =help(StockInfo)=.

#+BEGIN_SRC
Help on class StockInfo in module __main__:

class StockInfo(builtins.object)
 |  StockInfo(name: str, price: float, percent_change: float) -> None
#+END_SRC

Since our =NamedTuple= implementation is a sub-class, we have to scroll down a bit to find the attributes of the class in the =help= output, and the type annotations are hidden away as an =OrderedDict= in the =_fields= attribute.

#+BEGIN_SRC
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from _BaseStockInfo:
 |
 |  name
 |      Alias for field number 0
 |
 |  price
 |      Alias for field number 1
 |
 |  percent_change
 |      Alias for field number 2
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from _BaseStockInfo:
 |
 |  __annotations__ = OrderedDict([('name', <class 'str'>), ('price', ... ...
 |
 |  _field_defaults = {}
 |
 |  _field_types = OrderedDict([('name', <class 'str'>),
#+END_SRC



* DONE Three Completely Different Approaches to the FizzBuzz Problem :programming:python:OCaml:lisp:
CLOSED: [2020-03-11 Mon 22:49]
:PROPERTIES:
:EXPORT_FILE_NAME: fizzbuzz_approaches
:END:

Here's a solution to the classic infamous FizzBuzz problem in Python:

#+BEGIN_SRC python :results output :exports both
for i in range(1, 31):
    if i % 15 == 0:
        print("FizzBuzz")
    elif i % 3 == 0:
        print("Fizz")
    elif i % 5 == 0:
        print("Buzz")
    else:
        print(i)
#+END_SRC

#+RESULTS:
#+begin_example
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz
16
17
Fizz
19
Buzz
Fizz
22
23
Fizz
Buzz
26
Fizz
28
29
FizzBuzz
#+end_example

This program is really simple and is probably the most common approach. You just
need to understand how =if= statements work and you're good to go.

We can take this up a notch by using type-driven exhaustive pattern-matching so
that our programming language can actually tell us if we've made a mistake in
our implementation. Here's version 2 of the FizzBuzz program using the OCaml
programming language:

#+BEGIN_SRC ocaml :exports both
open Base

let () =
  for i = 1 to 30 do
    match Int.rem i 3, Int.rem i 5 with
    | 0, 0 -> Stdio.print_endline "FizzBuzz"
    | 0, _ -> Stdio.print_endline "Fizz"
    | _, 0 -> Stdio.print_endline "Buzz"
    | _, _ -> Stdio.printf "%d\n" i
  done
#+END_SRC

#+RESULTS:
#+begin_example
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz
16
17
Fizz
19
Buzz
Fizz
22
23
Fizz
Buzz
26
Fizz
28
29
FizzBuzz
#+end_example

Notice the =match= expression right after the =for= loop. OCaml has a really
powerful type system that can catch some tricky edge cases in our logic at
compile time. The function =Int.rem= is just like modulo in other languages (I'm
using the =Base= alternate standard library for OCaml---the default language
comes with a =mod= operator). All the =match= expression in the code above is
doing is saying: "If i mod 3 is 0 and i mod 5 is 0, then print FizzBuzz, else if
i mod 3 is 0 and i mod 5 is anything, then print Fizz, else if i mod 3 is
anything and i mod 5 is 0, then print Buzz, else print i if both are anything".

That looks an awful lot like a standard =if= statement to me. The real advantage
comes when you forget to include a case:

#+BEGIN_SRC ocaml :exports both
open Base

let () =
  for i = 1 to 30 do
    match Int.rem i 3, Int.rem i 5 with
    | 0, 0 -> Stdio.print_endline "FizzBuzz"
    | 0, _ -> Stdio.print_endline "Fizz"
    | _, 0 -> Stdio.print_endline "Buzz"
    (* | _, _ -> Stdio.printf "%d\n" i <-- commented out *)
  done
#+END_SRC

#+RESULTS:
#+begin_example
Characters 45-207:
  ....match Int.rem i 3, Int.rem i 5 with
      | 0, 0 -> Stdio.print_endline "FizzBuzz"
      | 0, _ -> Stdio.print_endline "Fizz"
      | _, 0 -> Stdio.print_endline "Buzz"
Warning 8: this pattern-matching is not exhaustive.
Here is an example of a case that is not matched:
(1, 1)
Exception: Match_failure ("//toplevel//", 228, 4).
Raised at file "//toplevel//", line 231, characters 14-40
Called from file "toplevel/toploop.ml", line 180, characters 17-56
#+end_example

This is really cool---OCaml's compiler knows when the =match= statement doesn't
cover all the possible cases and will even give you an example of a case that
wasn't met! Once we include that last case, the program will successfully
compile. Depending how you structure your pattern matching, the compiler will
sometimes even tell you if you've used redundant or incorrect cases. It's a
killer feature and I wish more languages had it. Exhaustive pattern matching
like this is usually unique to strongly typed functional programming languages,
although Rust has also adopted this feature and I'm sure others will follow.

Now for the third and wildest approach to solving the FizzBuzz problem---this
time with Clojure. Clojure is a Lisp dialect that emphasizes functional
programming and immutable data structures. This language also happens to have
great support for lazy sequences---a feature that this particular FizzBuzz
program uses heavily.

A lazy sequence is not evaluated immediately---instead, it delays its evaluation
until it is needed by another function.

To illustrate this, here's the documentation for the =cycle= function in
Clojure:

#+BEGIN_SRC clojure :results output :exports both :eval never-export
(doc cycle)
#+END_SRC

#+RESULTS:
: -------------------------
: clojure.core/cycle
: ([coll])
:   Returns a lazy (infinite!) sequence of repetitions of the items in coll.

How do you use these so-called infinite sequences without using up all the
memory in your computer? The key to using lazy sequences is that these functions
are not evaluated until they are needed by another function. So running this:

#+BEGIN_SRC clojure
(cycle '("Fizz" "Buzz"))
#+END_SRC

would just hang the Clojure session because it's waiting to be evaluated. Let's
fix that by taking some values from this infinite sequence.

#+BEGIN_SRC clojure :exports both :eval never-export
(take 10 (cycle '("Fizz" "Buzz")))
#+END_SRC

#+RESULTS:
| Fizz | Buzz | Fizz | Buzz | Fizz | Buzz | Fizz | Buzz | Fizz | Buzz |

Now we can write a completely different FizzBuzz implementation leveraging the
power of these lazy sequences. I modified the example from [[http://www.petecorey.com/blog/2018/07/09/golfing-for-fizzbuzz-in-clojure-and-elixir/][this blog post]] so the
output would match my Python and OCaml programs.

#+BEGIN_SRC clojure :results output :exports both :eval never-export
(doseq
    [x
     (->>
      (map list
           (range 31)
           (cycle ["Fizz" "" ""])
           (cycle ["Buzz" "" "" "" ""]))
      (rest)
      (map (fn [lst]
             (let [i (first lst)]
               (if (or (= 0 (mod i 3)) (= 0 (mod i 5)))
                 (apply str (concat (rest lst)))
                 (apply str (concat lst)))))))]
  (println x))
#+END_SRC

#+RESULTS:
#+begin_example
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz
16
17
Fizz
19
Buzz
Fizz
22
23
Fizz
Buzz
26
Fizz
28
29
FizzBuzz
#+end_example

The four lines of code below is the heart of the program. It uses the =range=
function to assign numbers to the first elements of the lists and then uses the
two =cycle= functions to assign either the empty string, Fizz, or Buzz to the
second and third elements of the list respectively. It's a really neat
declarative way of implementing FizzBuzz and my mind was completely blown when I
understood what the program really does.

#+BEGIN_SRC clojure :exports both :eval never-export
(map list
     (range 31)
     (cycle ["Fizz" "" ""])
     (cycle ["Buzz" "" "" "" ""]))
#+END_SRC

#+RESULTS:
|  0 | Fizz | Buzz |
|  1 |      |      |
|  2 |      |      |
|  3 | Fizz |      |
|  4 |      |      |
|  5 |      | Buzz |
|  6 | Fizz |      |
|  7 |      |      |
|  8 |      |      |
|  9 | Fizz |      |
| 10 |      | Buzz |
| 11 |      |      |
| 12 | Fizz |      |
| 13 |      |      |
| 14 |      |      |
| 15 | Fizz | Buzz |
| 16 |      |      |
| 17 |      |      |
| 18 | Fizz |      |
| 19 |      |      |
| 20 |      | Buzz |
| 21 | Fizz |      |
| 22 |      |      |
| 23 |      |      |
| 24 | Fizz |      |
| 25 |      | Buzz |
| 26 |      |      |
| 27 | Fizz |      |
| 28 |      |      |
| 29 |      |      |
| 30 | Fizz | Buzz |

I never knew FizzBuzz could be solved in so many different ways and it's a neat
little problem to illustrate the strengths and styles of different programming
languages: Python is great for writing legible imperative code that's simple yet
expressive. OCaml is great for writing safe strongly typed code with exhaustive
compiler checks when you need them. Clojure is great for writing highly dynamic
functional code which uses lots of abstractions that makes working with data
much easier.


* DONE Remote Linux Process Hacking through SSH :programming:lisp:linux:
CLOSED: [2020-03-09 Mon 22:10]
:PROPERTIES:
:EXPORT_FILE_NAME: remote_process_hacking
:END:

There's this really cool [[https://www.youtube.com/playlist?list=PLBgJcoaU2hl-JnoVOzjYB5qk_PfYjPm-I][process hacking series]] on YouTube by Keist Zenon. He
uses the programming language Common Lisp to interact with processes on his
Linux machine. I tried following the tutorial on my Mac, but macOS does not have
the same =ptrace= commands and system call interfaces as Linux so this did not
work out. However, I have VirtualBox set up on my Mac with a Debian VM which I
use whenever I need Linux.

Here's the idea: is it possible to hack processes on my Linux VM from Emacs on
my Mac? I found out that it's not only possible, but it's actually surprisingly
easy.

** Configuring the Virtual Machine
# :PROPERTIES:
# :HEADER-ARGS:sh: :dir /ssh:debian-box:/home/samarth/cl-ptrace
# :END:

First you'll need to set up a Bridged Adapter on your VirtualBox VM to allow
your host machine to connect to it via SSH. [[https://www.youtube.com/watch?v=ErzhbUusgdI][This YouTube tutorial]] was pretty
helpful. You'll just have to change how you enable the SSH service on your Linux
VM---I'm on Debian so I had to run the command

#+BEGIN_SRC sh :exports both :eval never-export
systemctl status ssh | cat | grep active
#+END_SRC

#+RESULTS:
: Active: active (running) since Fri 2020-03-13 18:24:14 EDT; 33s ago

to see if SSH was enabled.

To attach and manipulate this process, we need to use the =ptrace= function. You
can see the documentation for it with the command =man 2 ptrace= (2 stands for
the second section of the manual, since we want the C system call function for
=ptrace= instead of the general UNIX command). We could use C for process
hacking, but it's a lot nicer to use an interactive language like Lisp. Plus,
it's possible to interact with a remote Lisp REPL from your host machine's local
Emacs instance through SSH. Common Lisp is pretty amazing---I don't know if many
other programming languages have these features.

Clone [[https://github.com/k-stz/cl-ptrace][Keist's GitHub repo]] to your VM to get his Common Lisp library for process
hacking with =ptrace=. The code here is essentially the same as the tutorial,
except you might have to remove the line that says

#+BEGIN_SRC common-lisp
(:file "cl-ptrace/async-functions")
#+END_SRC

since that file doesn't exist in the repo for some reason. Install your Common
Lisp implementation of choice (I use =sbcl= since it's well-supported on most
platforms) and follow the instructions on the [[https://www.quicklisp.org/beta/][Quicklisp website]] to install
Quicklisp. Quicklisp is the unofficial package manager for Common Lisp.

Once you've successfully installed Quicklisp, you need to set up a Lisp REPL on
the remote VM so it can talk to your local Emacs editor. Quit out of your =sbcl=
repl and run it as root. We need Lisp to run as root since the =ptrace= system
calls need root access.

#+BEGIN_SRC sh
sudo sbcl
#+END_SRC

In his tutorial, Kaiste avoided this problem by running Emacs as root since he
was hacking processes from the same machine. However, we don't want to do this
since running Emacs as root can be dangerous, plus we are trying to hack
processes on our /remote/ machine from our /local (host)/ Emacs editor, so
running Emacs locally as root wouldn't really be useful.

Use Quicklisp to load/install =ASDF= and =slynk=, and then create a =slynk=
server on port 4006. You can use the default port 4005 if it's open.

#+BEGIN_SRC common-lisp
(ql:quickload :asdf)
(ql:quickload :slynk)
(slynk:create-server :port 4006)
#+END_SRC

If you get stuck, follow the instructions in [[https://joaotavora.github.io/sly/#Setting-up-the-Lisp-image][the SLY manual]], but I think
Quicklisp makes this process a bit easier.

Now fire up a new terminal and get your VM's ip address. On Debian, the command
is

#+BEGIN_SRC sh :eval never-export
hostname -I
#+END_SRC

#+RESULTS:
: 192.168.1.4

After that, SSH into your VM from your /host/ machine to create an SSH tunnel
that we'll take advantage of later.

#+BEGIN_SRC sh
ssh -L4006:localhost:4006 <username>@<ip-address>
#+END_SRC

Change =4006= to the port that =slynk= is using to run your Lisp server, and
change the =<username>= and =<ip-address>= fields. Remember to run this command
from your host machine, not the VM.

Once your SSH tunnel is set up, follow the instructions in section 8.1.3 of the
SLY manual (linked above) to configure Emacs to translate filenames between the
remote and host machines. Make sure you have TRAMP installed and working in
Emacs. Now you can connect to your VM from your host machine's Emacs using
TRAMP. =C-x C-f /ssh:<username>@<ip-address>= should do the trick. Now you can
navigate to the =cl-ptrace= repo.

The setup is pretty much over: now we can start hacking. Compile the =spam.c=
file in the =cl-ptrace= repo on your VM into the executable =spam= and run it.

#+BEGIN_SRC sh
gcc spam.c -o spam
./spam
#+END_SRC

We want to get the process id (=pid=) of this =spam= program so we can interact
with it. To do this, run the command

#+NAME: spam-pid
#+BEGIN_SRC sh :exports both :eval never-export
ps -a | grep spam | awk '{ print $1 }'
#+END_SRC

#+RESULTS: spam-pid
: 1543

We can then display information about the process with =top=. You can get a
nicer output by using the =htop= program.

#+BEGIN_SRC sh :var PID=spam-pid
top -p $PID
#+END_SRC

We can even limit the output of =top= to just get the CPU usage. The =sed=
commands are just for making the output nicer.

#+BEGIN_SRC sh :var PID=spam-pid :exports both :eval never-export
top -p $PID -n 2 -b | grep Cpu | sed 's/\:/\: /' | sed 's/us,.*/ /'
#+END_SRC

#+RESULTS:
| %Cpu(s): |  53.6 |
| %Cpu(s): | 100.0 |

Notice that the =spam= program is taking up over 90% of the CPU since it's an
infinite =while= loop in a single-threaded process.

** Hacking in Emacs

Next, switch back to Emacs (on the host machine) and make sure you're in the
remote =cl-ptrace= repo via TRAMP. We want to connect to the remote Lisp server
from Emacs, so run the command =M-x sly-connect=, keep the default host as
=localhost=, and change the port to the =slynk= server port.

Now you have a local Lisp REPL that is connected to your VM via the SSH tunnel
we created earlier. Load the file =cl-ptrace.asd= with the command =M-x
sly-load-file=. The file is on the remote VM, but this isn't a problem because
TRAMP should be configured to handle the remote filenames (we did this earlier).
This should load the file into the =sly= REPL. Then run =(asdf:load-system
"cl-ptrace")= to load the =cl-ptrace= library into the REPL, and run
=(in-package :cl-ptrace)= to start using the library.

Make sure that you're root by running the function =(am-i-root?)=. It should
return =T=. Now you've successfully created a mechanism to hack remote processes
from your local machine using Common Lisp and Emacs. Go ahead and follow along
with the rest of Kaiste's videos---they're amazing.

* Interactive OCaml Development :OCaml:programming:
CLOSED: [2020-03-08 Sun 22:06]
:PROPERTIES:
:EXPORT_FILE_NAME: interactive_ocaml_development
:END:

Interactive development features are mostly found in dynamically-typed
interpreted programming languages like Python or JavaScript. While OCaml is a
statically-typed compiled language, it is still possible to program in an
interactive style using a REPL. However, OCaml will never be quite as flexible
and interactive as something like Lisp because of its greatest feature: the
strong static type system.

** Testing functions using the REPL

One of the nicest features of OCaml is that is has both a byte-code compiler
(=ocamlc=) and a native-code compiler (=ocamlopt=). This means that you can
develop programs in an interactive, [[http://www.paulgraham.com/progbot.html][bottom-up]] style using the REPL. Bottom-up
development is a technique most-often leveraged by Lisp programmers in which you
can write a single function, compile it and send it to the REPL, and then test
that function interactively in the REPL. OCaml's fast bytecode compiler makes it
possible to use this technique that is usually unique to Lisps and interpreted
languages.

*** Sending code to the REPL in Emacs
I'll describe the process for interactive development using Emacs which is my
text editor of choice. Similar techniques should exist for other editors such as
VS Code or Vim.

OCaml's REPL is called =utop= and it has a lot of nice features that make it
well-suited for interactive development. If you're using Emacs, you can send
your OCaml code to =utop= to be evaluated. Here's an example of using =utop= to
test a single function.

#+BEGIN_SRC ocaml
open Base

let sum_list list = List.fold ~f:( + ) ~init:0 list
#+END_SRC

To send this code to =utop=, highlight it and press =C-x C-r= (or =M-x
utop-eval-region RET=). You can even send an entire buffer to =utop= by pressing
=C-c C-b= via the function =utop-eval-buffer=. If you use the =dune= build
system and configure Emacs appropriately (instructions on how to do this are in
the [[https://github.com/ocaml-community/utop#main-setup][utop documentation]]), a dialog will pop up saying: "utop command line: opam
config exec -- dune utop . -- -emacs". Press =RET= to evaluate the code.

You might have seen a message saying "Error: unbound module Base". This code
uses [[https://opensource.janestreet.com/base/][Jane Street's Base alternative standard library]] which makes things a bit
more complicated, since =utop= does not know about Base by default.

To solve this, create a new file in the same directory called =.ocamlinit=.
=utop= reads this file before starting and executes the commands specified. You
just need to include a single line to load the Base library into =utop=:

#+BEGIN_SRC ocaml
#require "base";;
#+END_SRC

Now try the previous steps again to load the =sum_list= function into =utop=. If
this still doesn't work, make sure your =opam= environment is set up correctly
by running the command =opam switch= in a terminal and following the
instructions.

Once everything is working, go ahead and test the function in the REPL by
running =sum_list [1; 2; 3];;= (the double semicolons at the end of the line are
important because =utop= uses them to mark the end of an expression). If you
want to make changes to the function, simply switch back to the OCaml buffer,
edit the code, and send it back to =utop=.

*** Working with multiple files in the REPL

The technique I described above works great within a single file, but things get
complicated once you send code from multiple files to the same =utop= instance.
For example, say you made the =sum_list= function within a file called
=test.ml= and sent that code to =utop=. Now you want to use =Test.sum_list=
within another file, so you create a new file called =use_test.ml= which
implements a new function:

#+BEGIN_SRC ocaml
let double_sum_list list = (Test.sum_list list) * 2
#+END_SRC

Now when you go to send this new function to =utop=, you run into an error:
"Error: Unbound module Test".

Here's the full sample =utop= session:

#+BEGIN_SRC
utop[0]> open Base

let sum_list list = List.fold ~f:( + ) ~init:0 list
;;
val sum_list : int list -> int = <fun>
utop[1]> sum_list [1; 2; 3];;
- : int = 6
utop[2]> let double_sum_list list = (Test.sum_list list) * 2
;;

Error: Unbound module Test
#+END_SRC

Since OCaml isn't really made to be an interactive programming language, there
isn't a clean solution for this problem as far as I'm aware. However, you can
hack around this using the same =.ocamlinit= file that I mentioned before.

Kill =utop= and modify the =.ocamlinit= file to look like this:

#+BEGIN_SRC ocaml
#require "base";;
#mod_use "test.ml";;
#+END_SRC

The =#mod_use= function tells =utop= to import the given file into the REPL as a
module. This is important because it lets us call =sum_list= as =Test.sum_list=.
=#mod_use= essentially wraps up the functions from the file into a module and
sends that module to be evaluated in the REPL, which is basically how the OCaml
compiler treats OCaml files. We don't want to change our development style to
work with the REPL since =utop= is configurable enough.

There is one caveat with this approach: you have to edit =.ocamlinit= and
restart =utop= whenever you create a new file. If you switch files (say you were
sending code from =use_test.ml= to the REPL but now want to work with
=test.ml=), you have to restart =utop= each time to ensure that it has the most
up-to-date version of all your files/modules. This is a bit of a pain and I'm
not sure if there's a solution to this problem given OCaml's static nature.

** Pretty-printing

A major part of interactive development is seeing the results of functions in
the REPL. Since OCaml has a strong type system without dynamic dispatch, you can
only print strings---this means that you have to write functions to convert your
user-defined types (which are everywhere in idiomatic OCaml code) to strings
each time you want to print them. This is a pain, but luckily there's an elegant
solution: [[https://github.com/ocaml-ppx/ppx_deriving#plugin-show][ppx]].

=ppx= is a syntax extension to OCaml which acts as a macro that automatically
generates code to pretty-print a custom type (=ppx_deriving.show=), generate
equality functions (=ppx_deriving.eq=), etc.

To pretty-print custom types annotated with =[@@deriving show]= in =utop=, you'll need to
once again modify the =.ocamlinit= file and add the following line:

#+BEGIN_SRC ocaml
#install_printer Module.pp;;
#+END_SRC

where =Module= is the name of the module which has the corresponding =pp=
function. Here's an example of one such module that pretty-prints a custom
hash-table with the =Depths= module, where =type t=... =[@@deriving show]= refers
to the =Resolver.t= type:

#+BEGIN_SRC ocaml
module Depths = struct
  type t = (string, int) Hashtbl.t

  let pp ppf values =
    Caml.Format.open_hovbox 1;
    Caml.Format.print_cut ();
    if Hashtbl.length values = 0
    then Caml.Format.fprintf ppf "@[<hov 2>{}@]"
    else (
      Caml.Format.fprintf ppf "@[<hov 1>{@ @]";
      Hashtbl.iteri values ~f:(fun ~key ~data ->
          Caml.Format.fprintf ppf "@[<hov 2>%s: %d,@ @]" key data);
      Caml.Format.fprintf ppf "@[<hov 1>}@]");
    Caml.Format.close_box ()
  ;;
end

type t =
  { statements : Parser.statement list
  ; scopes : Scopes.t
  ; depths : Depths.t
  ; parsed_statements : Parser.statement list
  }
[@@deriving show]
#+END_SRC

Here are the corresponding lines in =.ocamlinit= which tell =utop= which types
to pretty-print (the above code is from a file called =resolver.ml=):

#+BEGIN_SRC ocaml
#install_printer Resolver.pp;;
#install_printer Resolver.Depths.pp;;
#+END_SRC

Now =utop= knows to call the respective =pp= function whenever it needs to print
type information for the corresponding module. I needed to write the custom
=Depths.pp= function by hand since =ppx_deriving.show= is not powerful enough to
work for all custom types. This is one drawback of strong static type systems.

** Tracing function execution

Say you want to now debug the =resolve= function in your =Resolver= module, but
the return value of =resolve= is of type =Resolver.t=. If you didn't have the
=[@@deriving show]= =ppx= annotation on =type t= and didn't write the custom
=Scopes.pp= and =Depths.pp= functions, this would be part of the output of
tracing a call to =Resolver.resolve= in =utop= (I cut off the rest of the output
since it wasn't important):

#+BEGIN_SRC ocaml
utop[1]> #trace Resolver.resolve;;
Resolver.resolve is now traced.
utop[2]> Scanner.make_scanner "var x = 1; { var y = 2; }"
|> Scanner.scan_tokens
|> Parser.make_parser
|> Parser.parse
|> Resolver.make_resolver
|> Resolver.resolve;;
Resolver.resolve <--
  {Resolver.statements =
    [Parser.VarDeclaration
      {Parser.name =
        {Scanner.token_type = Scanner.Identifier; lexeme = "x";
         literal = Value.LoxNil; line = 1};
       init =
        Parser.Literal
         {Parser.token =
           {Scanner.token_type = Scanner.Number; lexeme = "1";
            literal = Value.LoxNumber 1.; line = 1};
          value = Value.LoxNumber 1.}};
     Parser.Block
      [Parser.VarDeclaration
        {Parser.name =
          {Scanner.token_type = Scanner.Identifier; lexeme = "y";
           literal = Value.LoxNil; line = 1};
         init =
          Parser.Literal
           {Parser.token =
             {Scanner.token_type = Scanner.Number; lexeme = "2";
              literal = Value.LoxNumber 2.; line = 1};
            value = Value.LoxNumber 2.}}]];
   scopes = <abstr>; depths = <abstr>;
#+END_SRC

Notice this last line: =scopes = <abstr>; depths = <abstr>;=. The =<abstr>=
value indicates that OCaml does not know how to print values of the =Scopes.t=
or =Depths.t= type since there are no dedicated =pp= functions for those types.

Once I added the =[@@deriving show]= annotation back to =type t=, wrote the
=Scopes.pp= and =Depths.pp= functions, and added the relevant =#install_printer=
lines to =.ocamlinit=, this was the full output of the same trace to
=Resolver.resolve=:

#+BEGIN_SRC ocaml
utop[1]> #trace Resolver.resolve;;
Resolver.resolve is now traced.
utop[2]> Scanner.make_scanner "var x = 1; { var y = 2; }"
|> Scanner.scan_tokens
|> Parser.make_parser
|> Parser.parse
|> Resolver.make_resolver
|> Resolver.resolve;;
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "1"; literal = (Value.Value.LoxNumber 1.); line = 1 };
             value = (Value.Value.LoxNumber 1.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "1"; literal = (Value.Value.LoxNumber 1.); line = 1 };
             value = (Value.Value.LoxNumber 1.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                 line = 1 };
               value = (Value.Value.LoxNumber 2.) })
          })
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = { y: declared, }; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = { y: declared, }; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = { y: declared, }; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve <--
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
Resolver.resolve -->
  { Resolver.Resolver.statements =
    [(Parser.Parser.Expression
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
             value = (Value.Value.LoxNumber 2.) }))
      ];
    scopes = {}; depths = {};
    parsed_statements =
    [(Parser.Parser.VarDeclaration
        { Parser.Parser.name =
          { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
            lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
          init =
          (Parser.Parser.Literal
             { Parser.Parser.token =
               { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                 lexeme = "1"; literal = (Value.Value.LoxNumber 1.);
                 line = 1 };
               value = (Value.Value.LoxNumber 1.) })
          });
      (Parser.Parser.Block
         [(Parser.Parser.VarDeclaration
             { Parser.Parser.name =
               { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
                 lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
               init =
               (Parser.Parser.Literal
                  { Parser.Parser.token =
                    { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                      lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                      line = 1 };
                    value = (Value.Value.LoxNumber 2.) })
               })
           ])
      ]
    }
- : Resolver.t =
{ Resolver.Resolver.statements =
  [(Parser.Parser.Expression
      (Parser.Parser.Literal
         { Parser.Parser.token =
           { Scanner.Scanner.token_type = Scanner.Scanner.Number;
             lexeme = "2"; literal = (Value.Value.LoxNumber 2.); line = 1 };
           value = (Value.Value.LoxNumber 2.) }))
    ];
  scopes = {}; depths = {};
  parsed_statements =
  [(Parser.Parser.VarDeclaration
      { Parser.Parser.name =
        { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
          lexeme = "x"; literal = Value.Value.LoxNil; line = 1 };
        init =
        (Parser.Parser.Literal
           { Parser.Parser.token =
             { Scanner.Scanner.token_type = Scanner.Scanner.Number;
               lexeme = "1"; literal = (Value.Value.LoxNumber 1.); line = 1 };
             value = (Value.Value.LoxNumber 1.) })
        });
    (Parser.Parser.Block
       [(Parser.Parser.VarDeclaration
           { Parser.Parser.name =
             { Scanner.Scanner.token_type = Scanner.Scanner.Identifier;
               lexeme = "y"; literal = Value.Value.LoxNil; line = 1 };
             init =
             (Parser.Parser.Literal
                { Parser.Parser.token =
                  { Scanner.Scanner.token_type = Scanner.Scanner.Number;
                    lexeme = "2"; literal = (Value.Value.LoxNumber 2.);
                    line = 1 };
                  value = (Value.Value.LoxNumber 2.) })
             })
         ])
    ]
  }
utop[8]>
#+END_SRC

Notice how =utop= now knows how to print the =Scopes.t= and =Depths.t= types,
like =scopes = { y: declared, }; depths = {};=, instead of just =scopes =
<abstr>; depths = <abstr>;=. This technique is incredibly useful for debugging
by tracing functions in the REPL and using the REPL interactively in general.

I hope this overview of interactive OCaml development with =utop= was useful.
Even though OCaml is a language that has an uncompromisingly strict static type
system, it's still possible to get some of the useful interactive features
of more dynamic languages like Lisp through a configurable plugin-based REPL and
syntax extensions that help minimize boilerplate. Sometimes you really can have
your cake and eat it too!

* Footnotes
* COMMENT Local Variables                          :ARCHIVE:
# Local Variables:
# eval: (org-hugo-auto-export-mode)
# End:
